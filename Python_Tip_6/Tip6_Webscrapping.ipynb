{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "345f0092-c643-4f8b-8e21-b3d2424e3210",
   "metadata": {},
   "source": [
    "<h1 class=\"title\">Python Tips<br>#6 Webscrapping</h1>\n",
    "<br>\n",
    "<center>Michael Siebel</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d924f3-4cc1-40f9-a6bd-91e08d469cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "document.body.dispatchEvent(new KeyboardEvent('keydown', {key:'s', keyCode: 83, ctrlKey: true}))"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "function toggler(){\n",
       "    if(window.already_toggling){\n",
       "        // Don't add multiple buttons.\n",
       "        return 0\n",
       "    }\n",
       "    let btn = $('div.input > div.inner_cell').append('<button>Show/Hide Code</button>')\n",
       "        .children('button');\n",
       "    btn.on('click', function(e){\n",
       "        let tgt = e.currentTarget;\n",
       "        $(tgt).parent().children('div.input > div.inner_cell > div.input_area').toggle()\n",
       "    })\n",
       "    window.already_toggling = true;\n",
       "}\n",
       "// Since javascript cells are executed as soon as we load\n",
       "// the notebook (if it's trusted), and this cell might be at the\n",
       "// top of the notebook (so is executed first), we need to\n",
       "// allow time for all of the other code cells to load before\n",
       "// running. Let's give it 1 second.\n",
       "\n",
       "setTimeout(toggler, 1000);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1.title {\n",
       "    text-align: center;\n",
       "    font-size: 2.25em;\n",
       "    font-weight: bold;\n",
       "    font-family: 'Montserrat', sans-serif !important;\n",
       "    margin-top: 1.5em !important; \n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.cell:nth-of-type(2) {\n",
       "    display: none !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%run ../HTML_Functions.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0f76f-ee8e-4bce-89c4-98ef4e5f1957",
   "metadata": {},
   "source": [
    "Webscrapping is a very important skill to learn if you are interested in natural language processing.  While webscrapping text requires a strong understanding of HTML and CSS, webscrapping tables does not involve much understanding of HTML and CSS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268307f2-1f07-4ec6-aeb5-74e7f9bdc43e",
   "metadata": {},
   "source": [
    "# Website\n",
    "\n",
    "Recently, I webscrapped a crosswalk between FIPS, county, and State--which was super simple.  The table looks like this:\n",
    "\n",
    "![pic1.jpg](pic1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8701abcb-8bb6-4246-9f7e-59903062b849",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "\n",
    "The libraries we will use for this is requests, which loads a website into Python, and BeautifulSoup which parses it, enabling us to convert it from HTML into another format such as a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d65014-8fc0-4f7f-b9d0-10f5e160a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "## Main Data Wrangling Library\n",
    "import pandas as pd\n",
    "## Get webpage\n",
    "import requests\n",
    "## Parse webpage\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da519bf2-f1df-4db1-9604-bb22d954728d",
   "metadata": {},
   "source": [
    "# Get Webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1ee3c97-c99f-4f62-acb3-da77eaa65e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\">\n",
      " <head>\n",
      "  <!-- Google Tag Manager -->\n",
      "  <script>\n",
      "   (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\n",
      "new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\n",
      "j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n",
      "'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n",
      "})(window,document,'script','dataLayer','GTM-MJ48553');\n",
      "  </script>\n",
      "  <!-- End Google Tag Manager -->\n",
      "  <meta content=\"IE=edge,chrome=1\" http-e\n"
     ]
    }
   ],
   "source": [
    "# Get Webpage\n",
    "url = \"https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697\"\n",
    "req = requests.get(url)\n",
    "# Parse Webpage\n",
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "print(soup.prettify()[:555])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fe119e-caca-43b2-97e4-ceacb758192c",
   "metadata": {},
   "source": [
    "# Inspect Webpage\n",
    "\n",
    "Now we have to sift through the HTML code to find the table.  Sounds hard, but if we go to the webpage, right click on the page and select \"inspect\" (or hit Shift + Ctrl + I in Google Chrome), the web browser will show us the HTML code.  In particular, nearly all web browser will have a selector tool to find the HTML element.  Here it is in Google Chrome:\n",
    "\n",
    "![pic2.jpg](pic2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ccf6c5-2931-4a25-a5f9-bc2ff60ef66a",
   "metadata": {},
   "source": [
    "# Grab HTML Element"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bbaa38c2-3155-4c5b-86a7-476e5e6dcf01",
   "metadata": {},
   "source": [
    "The element we want is a <table> with class='data'.  Using BeautifulSoup's find() we can isolate this element and then use Pandas read_html() to convert it to a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39327c03-1669-43bf-911e-0d2c576bab82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Name</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>Blount</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS     Name State\n",
       "0  1001  Autauga    AL\n",
       "1  1003  Baldwin    AL\n",
       "2  1005  Barbour    AL\n",
       "3  1007     Bibb    AL\n",
       "4  1009   Blount    AL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract Data\n",
    "table = soup.find('table', attrs={'class': 'data'})\n",
    "# Convert from HTML to Pandas Dataframe\n",
    "df = pd.read_html(str(table))[0]\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0adca-124a-4c1c-afbf-5c4d55af45f8",
   "metadata": {},
   "source": [
    "# Export as CSV\n",
    "\n",
    "The final step is to export it as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16dc00-f742-4890-bac6-60126af05d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as CSV\n",
    "df.to_csv(\"FIPS_to_County.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567be2fc-a028-4dd7-8acf-6d7a572fed58",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Government webpages and Wikipedia generally are often easy to scrape as they do not carry lots of ads and JavaScript code.  If the element you are scraping is a table, there is generally little parsing required, and therefore could be a useful skill to learn even if you are not interested in learning the in's and out's of web development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52515b62-159f-42ba-964e-b419936a16b6",
   "metadata": {},
   "source": [
    "# Save Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "274e5721-58cd-406f-8254-8cca3c27a11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "document.body.dispatchEvent(new KeyboardEvent('keydown', {key:'s', keyCode: 83, ctrlKey: true}))"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Tip6_Webscrapping.ipynb to html_toc\n",
      "[NbConvertApp] Writing 369765 bytes to Tip6_Webscrapping.html\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Javascript\n",
    "\n",
    "display(Javascript(\n",
    "    \"document.body.dispatchEvent(\"\n",
    "    \"new KeyboardEvent('keydown', {key:'s', keyCode: 83, ctrlKey: true}\"\n",
    "    \"))\"\n",
    "))\n",
    "\n",
    "!jupyter nbconvert --to html_toc \"Tip6_Webscrapping.ipynb\"  --ExtractOutputPreprocessor.enabled=False --CSSHTMLHeaderPreprocessor.style=stata-dark "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
