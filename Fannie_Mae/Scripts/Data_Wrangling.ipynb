{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Bad Bank Behavior<br>Analyzing Bank Mortgage during the 2007 Housing Bubble</center>  \n",
    "\n",
    "<center>Michael Siebel</center>\n",
    "<center>August 2020</center>\n",
    "<br>\n",
    "    \n",
    "## <center>Data Wrangling Script</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "<br>\n",
    "\n",
    "> To ETL data from: <br>\n",
    "1) Fannie Mae Loan Acquistion and Performance Data [Individual Mortgage Loans], <br>\n",
    "2) U.S. Census Bureau, Small Area Estimates Branch [Median Household Income by County], <br>\n",
    "3) Federal Reserve Economic Data (FRED) [Macroeconomic Data related to the Housing Market], <br>\n",
    "4) Federal Deposit Insurance Corporation (FDIC) Data [Information on FDIC-backed Banks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Functions.ipynb\n",
    "pd.set_option(\"display.max_columns\", 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Fannie Mae Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..Loaded year 2007 quarter Q1\n",
      "..Loaded year 2007 quarter Q2\n",
      "..Loaded year 2007 quarter Q3\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Collect file names\n",
    "fld = '..\\Data\\\\'\n",
    "x = []\n",
    "for file in os.listdir(fld):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.startswith(\"Acquisition_2007Q\"): \n",
    "        x.append(fld + filename)\n",
    "\n",
    "y = []\n",
    "for file in os.listdir(fld):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.startswith(\"Performance_2007Q\"): \n",
    "        y.append(fld + filename)\n",
    "\n",
    "# Load data\n",
    "df_acq = pd.DataFrame()\n",
    "df_per = pd.DataFrame()\n",
    "for i in range(len(x)):\n",
    "    acq, per = load_data(x[i], y[i])\n",
    "    acq['File Year'], per['File Year'] = x[i][20:24], x[i][20:24]\n",
    "    acq['File Quarter'], per['File Quarter'] = x[i][24:26], x[i][24:26]   \n",
    "    df_acq = pd.concat([df_acq, acq], ignore_index=True)\n",
    "    df_per = pd.concat([df_per, per], ignore_index=True)\n",
    "    print('..Loaded year', x[i][20:24], 'quarter', x[i][24:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary variables\n",
    "## remove Property Type, it only had one value    \n",
    "df_acq = df_acq.drop(labels=['Product Type'], axis=1)\n",
    "\n",
    "## remove Original Loan-to-Value (LTV) and use Original Combine Loan-to-Value (CLTV)\n",
    "df_acq = df_acq.drop(labels=['Original Loan-to-Value (LTV)'], axis=1)\n",
    "    \n",
    "## remove First Payment as this is of no value\n",
    "df_acq = df_acq.drop(labels=['First Payment'], axis=1)\n",
    "\n",
    "## remove Number of Units as it lacks data variation\n",
    "df_acq = df_acq.drop(labels=['Number of Units'], axis=1)\n",
    "\n",
    "## remove Relocation Mortgage Indicator\n",
    "df_acq = df_acq.drop(labels=['Relocation Mortgage Indicator'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2006 Data\n",
    "p1 = []\n",
    "for file in os.listdir(fld):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.startswith(\"Acquisition_2006Q\"): \n",
    "        p1.append(fld + filename)\n",
    "\n",
    "## 2002 Data\n",
    "p5 = []\n",
    "for file in os.listdir(fld):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.startswith(\"Acquisition_2002Q\"): \n",
    "        p5.append(fld + filename)\n",
    "\n",
    "# Load data\n",
    "## 2006 Data\n",
    "df_yr1 = pd.DataFrame()\n",
    "for i in range(len(p1)):\n",
    "    yr1, blk = load_data(p1[i])\n",
    "    yr1['File Year'] = p1[i][20:24]\n",
    "    yr1['File Quarter'] = p1[i][24:26]\n",
    "    df_yr1 = pd.concat([df_yr1, yr1], ignore_index=True)\n",
    "    print('..Loaded year', p1[i][20:24], 'quarter', p1[i][24:26])\n",
    "\n",
    "print('')\n",
    "## 2002 Data\n",
    "df_yr5 = pd.DataFrame()\n",
    "for i in range(len(p5)):\n",
    "    yr5, blk = load_data(p5[i])\n",
    "    yr5['File Year'] = p5[i][20:24]\n",
    "    yr5['File Quarter'] = p5[i][24:26]\n",
    "    df_yr5 = pd.concat([df_yr5, yr5], ignore_index=True)\n",
    "    print('..Loaded year', p5[i][20:24], 'quarter', p5[i][24:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate total loans by collapsing by Banks and File Date\n",
    "Loans2007 = df_acq.groupby(['Bank', 'File Year', 'File Quarter', 'Zip Code']) \\\n",
    "            .agg({'Original Mortgage Amount': 'mean'}).reset_index()\n",
    "Loans2006 = df_yr1.groupby(['Bank', 'File Year', 'File Quarter', 'Zip Code']) \\\n",
    "            .agg({'Original Mortgage Amount': 'mean'}).reset_index()\n",
    "Loans2002 = df_yr5.groupby(['Bank', 'File Year', 'File Quarter', 'Zip Code']) \\\n",
    "            .agg({'Original Mortgage Amount': 'mean'}).reset_index()\n",
    "\n",
    "# 1 Year change in total loans\n",
    "LoansYr1_Q1 = pd.merge(Loans2007.loc[Loans2007['File Quarter']=='Q1'], \n",
    "                       Loans2006.loc[Loans2006['File Quarter']=='Q1', :],\n",
    "                       on=['Bank', 'Zip Code'], how='left', suffixes=('', ' (Prev)'))    \n",
    "LoansYr1_Q2 = pd.merge(Loans2007.loc[Loans2007['File Quarter']=='Q2'], \n",
    "                       Loans2006.loc[Loans2006['File Quarter']=='Q2', :],\n",
    "                       on=['Bank', 'Zip Code'], how='left', suffixes=('', ' (Prev)'))    \n",
    "LoansYr1_Q3 = pd.merge(Loans2007.loc[Loans2007['File Quarter']=='Q3'], \n",
    "                       Loans2006.loc[Loans2006['File Quarter']=='Q3', :],\n",
    "                       on=['Bank', 'Zip Code'], how='left', suffixes=('', ' (Prev)'))    \n",
    "LoansYr1_Q4 = pd.merge(Loans2007.loc[Loans2007['File Quarter']=='Q4'], \n",
    "                       Loans2006.loc[Loans2006['File Quarter']=='Q4', :],\n",
    "                       on=['Bank', 'Zip Code'], how='left', suffixes=('', ' (Prev)'))    \n",
    "LoansYr1 = pd.concat([LoansYr1_Q1, LoansYr1_Q2, LoansYr1_Q3, LoansYr1_Q4], axis=0)\n",
    "LoansYr1.loc[LoansYr1['Original Mortgage Amount (Prev)'].isnull(), 'Original Mortgage Amount (Prev)'] = 0\n",
    "LoansYr1['Loan Change (1 Year)'] = LoansYr1['Original Mortgage Amount'] \\\n",
    "                                   - LoansYr1['Original Mortgage Amount (Prev)']\n",
    "LoansYr1 = LoansYr1[['Bank', 'Zip Code', 'File Quarter', \n",
    "                     'Original Mortgage Amount', 'Loan Change (1 Year)']]\n",
    "df_acq = pd.merge(df_acq, LoansYr1, on=['Bank', 'Zip Code', 'File Quarter', \n",
    "                                        'Original Mortgage Amount'], how='left', copy=False)\n",
    "print('Average change in 1 year:', np.mean(LoansYr1['Loan Change (1 Year)']).round(2))\n",
    "\n",
    "# 5 year change in total loans\n",
    "LoansYr5_Q1 = pd.merge(Loans2007.loc[Loans2007['File Quarter']=='Q1'], \n",
    "                       Loans2002.loc[Loans2002['File Quarter']=='Q1', :],\n",
    "                       on=['Bank', 'Zip Code'], how='left', suffixes=('', ' (Prev)'))    \n",
    "LoansYr5_Q2 = pd.merge(Loans2007.loc[Loans2007['File Quarter']=='Q2'], \n",
    "                       Loans2002.loc[Loans2002['File Quarter']=='Q2', :],\n",
    "                       on=['Bank', 'Zip Code'], how='left', suffixes=('', ' (Prev)'))    \n",
    "LoansYr5_Q3 = pd.merge(Loans2007.loc[Loans2007['File Quarter']=='Q3'], \n",
    "                       Loans2002.loc[Loans2002['File Quarter']=='Q3', :],\n",
    "                       on=['Bank', 'Zip Code'], how='left', suffixes=('', ' (Prev)'))    \n",
    "LoansYr5_Q4 = pd.merge(Loans2007.loc[Loans2007['File Quarter']=='Q4'], \n",
    "                       Loans2002.loc[Loans2002['File Quarter']=='Q4', :],\n",
    "                       on=['Bank', 'Zip Code'], how='left', suffixes=('', ' (Prev)'))    \n",
    "LoansYr5 = pd.concat([LoansYr5_Q1, LoansYr5_Q2, LoansYr5_Q3, LoansYr5_Q4], axis=0)\n",
    "LoansYr5.loc[LoansYr5['Original Mortgage Amount (Prev)'].isnull(), 'Original Mortgage Amount (Prev)'] = 0\n",
    "LoansYr5['Loan Change (5 Years)'] = LoansYr5['Original Mortgage Amount'] \\\n",
    "                                    - LoansYr5['Original Mortgage Amount (Prev)']\n",
    "LoansYr5 = LoansYr5[['Bank', 'Zip Code', 'File Quarter', \n",
    "                     'Original Mortgage Amount', 'Loan Change (5 Years)']]\n",
    "df_acq = pd.merge(df_acq, LoansYr5, on=['Bank', 'Zip Code', 'File Quarter', \n",
    "                                        'Original Mortgage Amount'], how='left', copy=False)\n",
    "print('Average change in 5 years:', np.mean(LoansYr5['Loan Change (5 Years)']).round(2))\n",
    "\n",
    "print('Shape:', df_acq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Target from Performance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Target Variable with Merge\n",
    "df = merge_df(df_acq, df_per)\n",
    "\n",
    "print('\\nThe number of features is:\\n', df.shape[1], sep='')\n",
    "print('\\nThe number of observations is:\\n', df.shape[0], sep='')\n",
    "target_values(df['Foreclosed'], data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop U.S. Terroritories due to missing data\n",
    "df = df[df['Property State'] != 'PR']\n",
    "df = df[df['Property State'] != 'GU']\n",
    "df = df[df['Property State'] != 'VI']\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates\n",
    "## Pre-file date values indicate a mortgage loan refinnanced during the date value\n",
    "df = df.sort_values(by=['Original Date'])\n",
    "df['Original Date'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fannie Mae Feature Recodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Variables\n",
    "df['Month'] = df['Original Date'].apply(lambda x: x.split('/')[0].strip()).apply(str)\n",
    "df['Year'] = df['Original Date'].apply(lambda x: x.split('/')[1].strip()).apply(str)\n",
    "df['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-Borrower Credit Score\n",
    "df['Harmonized Credit Score'] = ( df['Co-Borrower Credit Score'].loc[df['Co-Borrower Credit Score'].notnull()] * 0.25 ) \\\n",
    "                                  + ( df['Credit Score'].loc[df['Co-Borrower Credit Score'].notnull()] * 0.75 ) \n",
    "df['Harmonized Credit Score'].loc[df['Co-Borrower Credit Score'].isnull()] = df['Credit Score'].loc[df['Co-Borrower Credit Score'].isnull()]    \n",
    "\n",
    "print(df[['Harmonized Credit Score', 'Credit Score', 'Co-Borrower Credit Score']].head(10))\n",
    "df = df.drop(labels=['Credit Score', 'Co-Borrower Credit Score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mortgage Insurance %\n",
    "df['Mortgage Insurance %'] = np.where(df['Mortgage Insurance %'].isnull(), \\\n",
    "                                      0, df['Mortgage Insurance %'])\n",
    "df['Mortgage Insurance Type'][df['Mortgage Insurance %']==0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mortgage Insurance Type\n",
    "df['Mortgage Insurance Type'] = np.where(df['Mortgage Insurance Type'].isnull(), \\\n",
    "                                         0, 1)\n",
    "df['Mortgage Insurance Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse Refinance\n",
    "df['Loan Purpose'] = np.where(df['Loan Purpose'] != 'P', 1, df['Loan Purpose'])\n",
    "df['Loan Purpose'] = df['Loan Purpose'].replace('P', 0)\n",
    "df['Loan Purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode Number of Borrowers\n",
    "## Single Borrower binary\n",
    "## More than one borrower is 0\n",
    "df['Number of Borrowers'] = df['Number of Borrowers'].where(df['Number of Borrowers'] == 1, 0)\n",
    "df = df.rename(columns={'Number of Borrowers': 'Single Borrower'})\n",
    "df['Single Borrower'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Median Household Income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL County-level median household income from U.S. Census\n",
    "\n",
    "Aggregate on 3-digit zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import zipcode median household income\n",
    "income = pd.read_excel(\"..\\Data\\est07all.xls\",\n",
    "                       sheet_name = 'est07ALL', header = 2)\n",
    "income = income[['Name', 'Median Household Income']]\n",
    "income = income.rename(columns={'Name': 'County'})\n",
    "\n",
    "# Import county zipcode crosswalk\n",
    "crosswalk = pd.read_csv(\"..\\Data\\ZIP-COUNTY-FIPS_2017-06.csv\",\n",
    "                        header = 0)\n",
    "crosswalk = crosswalk[['ZIP', 'COUNTYNAME']]\n",
    "crosswalk = crosswalk.rename(columns={'ZIP': 'Zip Code', 'COUNTYNAME': 'County'})\n",
    "crosswalk['Zip Code'] = crosswalk['Zip Code'].astype(str)\n",
    "crosswalk['Zip Code'] = crosswalk['Zip Code'].str.slice(start=0, stop=-2)\n",
    "crosswalk['Zip Code'] = crosswalk['Zip Code'].astype(int)\n",
    "\n",
    "# Merge\n",
    "income_zipcode = pd.merge(income, crosswalk, on='County', how='outer')\n",
    "income_zipcode.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge zipcode crosswalk with \n",
    "income_zipcode = income_zipcode[['Median Household Income', 'Zip Code']]\n",
    "income_zipcode = income_zipcode.groupby('Zip Code').agg({'Median Household Income': 'mean'})\n",
    "df = pd.merge(df, income_zipcode, on='Zip Code', how='left')\n",
    "\n",
    "df['Median Household Income'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to keep bank values ~10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank Values\n",
    "df['Bank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode Bank to keep bank values ~10,000\n",
    "## Group Small loan banks\n",
    "Small_Loan = ['BISHOPS GATE RESIDENTIAL MORTGAGE TRUST', \n",
    "              'FREEDOM MORTGAGE CORP.', \n",
    "              'HSBC BANK USA, NATIONAL ASSOCIATION', 'PHH MORTGAGE CORPORATION (USAA FEDERAL SAVINGS BANK)', \n",
    "              'THIRD FEDERAL SAVINGS AND LOAN', 'WELLS FARGO BANK, N.A.']\n",
    "df = df.replace({'Bank': Small_Loan}, 'SMALL LOAN BANKS')\n",
    "\n",
    "## Collapse similar banks\n",
    "Chase = [\"CHASE HOME FINANCE (CIE 1)\", \"CHASE HOME FINANCE, LLC\"]\n",
    "df = df.replace({'Bank': Chase}, 'CHASE HOME FINANCE')\n",
    "GMAC = ['GMAC MORTGAGE, LLC (USAA FEDERAL SAVINGS BANK)', 'GMAC MORTGAGE, LLC']\n",
    "df = df.replace({'Bank': GMAC}, 'GMAC MORTGAGE')\n",
    "\n",
    "# Check updated Bank values\n",
    "df['Bank'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL FRED Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State to Region Conversion\n",
    "df = to_region(df, 'Property State')\n",
    "df['Region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Household Financial Obligations as a percent of Disposable Personal Income (FODSP)\n",
    "# Consumer Debt Service Payments as a Percent of Disposable Personal Income (CDSP)\n",
    "# S&P/Case-Shiller U.S. National Home Price Index (CSUSHPINSA)\n",
    "# Mortgage Debt Service Payments as a Percent of Disposable Personal Income  (MDSP)\n",
    "# Monthly Supply of Houses in the United States (MSACSR)\n",
    "# Homeowner Vacancy Rate for the United States (RHVRUSQ156N)\n",
    "fred_df = ['FODSP', 'CDSP', 'CSUSHPINSA', 'MDSP', 'MSACSR']\n",
    "fred_name = ['Household Financial Obligations', 'Consumer Debt Service Payment',\n",
    "             'National Home Price Index', 'Mortgage Debt Service Payments', 'Monthly Supply of Houses']\n",
    "fred_freq = ['qtr', 'qtr', 'yr', 'qtr', 'yr']\n",
    "\n",
    "for i in range(len(fred_df)):\n",
    "    fred_tmp = pd.read_csv('..\\Data\\FRED\\\\' + fred_df[i] + '.csv', header = 0)\n",
    "    if fred_freq[i]=='qtr':\n",
    "        df = fred_merge(fred_tmp, df, quarter=True, varname=fred_name[i])\n",
    "    else: df = fred_merge(fred_tmp, df, quarter=False, varname=fred_name[i])\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housing Inventory Estimate: Vacant Housing Units for Sale (ESALEUSQ176N)\n",
    "# Homeownership Rate for the United States (RHORUSQ156N)\n",
    "# Housing Inventory Estimate: Vacant Housing Units for Rent (ERENTUSQ176N)\n",
    "# Rental Vacancy Rate for the United States (RRVRUSQ156N)\n",
    "fred_df = ['ESALEUSQ176N', 'RHORUSQ156N', 'ERENTUSQ176N', 'RRVRUSQ156N']\n",
    "fred_name = ['Vacant Housing Units for Sale', 'Homeownership Rate', 'Vacant Housing Units for Rent',\n",
    "             'Rental Vacancy Rate']\n",
    "fred_freq = ['qtr', 'qtr', 'qtr', 'qtr']\n",
    "for i in range(len(fred_df)):\n",
    "    sub = len(fred_df[i]) - 7\n",
    "    fred_prefix= fred_df[i][0:sub]\n",
    "    fred_suffix= fred_df[i][-5:]\n",
    "    fred_tmp = {}\n",
    "    for region in ['NE', 'SO', 'MW', 'WE']:\n",
    "        fred_tmp[region] = pd.read_csv('..\\Data\\FRED\\\\' + fred_prefix + region + fred_suffix + '.csv', header = 0)\n",
    "    if fred_freq[i]=='qtr':\n",
    "        df = fred_merge_region(NE = fred_tmp['NE'], SO = fred_tmp['SO'], MW = fred_tmp['MW'], \n",
    "                               WE = fred_tmp['WE'], varname = fred_name[i], df_orig = df,\n",
    "                               quarter=True)\n",
    "    else:\n",
    "        df = fred_merge_region(NE = fred_tmp['NE'], SO = fred_tmp['SO'], MW = fred_tmp['MW'], \n",
    "                               WE = fred_tmp['WE'], varname = fred_name[i], df_orig = df,\n",
    "                               quarter=False)\n",
    "        \n",
    "print('Shape:', df.shape)\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL FDIC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to construct a list of quarterly dates\n",
    "present = '20071231'\n",
    "datetimes = pd.date_range('19980331', end=present, freq='Q')\n",
    "\n",
    "# get a list of zip files over which to iterate\n",
    "zip_files = glob.glob('..\\Data\\FDIC\\*.zip')\n",
    "\n",
    "# only want to return a subset of cols (save on memory usage!)\n",
    "used_columns = ['name', 'repdte', 'asset', 'lnlsnet', 'liab', 'dep', 'eqtot', 'numemp']\n",
    "used_dtypes = {'name': str, 'repdte': object, 'asset': float,\n",
    "               'lnlsnet': float, 'liab': float, 'eqtot': float, 'dep': float, 'numemp': float}\n",
    "\n",
    "# create a container for the individual dataframes\n",
    "dataframes = []\n",
    "\n",
    "for zip_file in zip_files:\n",
    "\n",
    "    tmp_buffer = zipfile.ZipFile(zip_file)\n",
    "    \n",
    "    # want to work with the assets and liabilities file\n",
    "    tmp_file = tmp_buffer.namelist()[5]\n",
    "    \n",
    "    tmp_dataframe = pd.read_csv(tmp_buffer.open(tmp_file),\n",
    "                                error_bad_lines=False,  # skips the mangled obs\n",
    "                                usecols=used_columns,\n",
    "                                dtype=used_dtypes,\n",
    "                                parse_dates=True)\n",
    "    \n",
    "    dataframes.append(tmp_dataframe)\n",
    "\n",
    "# concatenate the quarterly dataframes into a single data frame\n",
    "fdic = pd.concat(dataframes)\n",
    "\n",
    "# convert units from thousands to billions of USD\n",
    "fdic[['asset', 'lnlsnet', 'liab', 'dep', 'eqtot']] /= 1e6\n",
    "\n",
    "# convert units from nummber of people to thousands of people\n",
    "fdic['numemp'] /= 1e3\n",
    "\n",
    "# Group by bank\n",
    "## Group Bank of America\n",
    "BoA = fdic['name'].str.contains('Bank of America')\n",
    "fdic.loc[BoA, 'Bank'] = 'BANK OF AMERICA, N.A.'\n",
    "## Group Citi Mortgage\n",
    "Citi = fdic['name'].str.contains('Citibank|Citicorp')\n",
    "fdic.loc[Citi, 'Bank'] = 'CITIMORTGAGE, INC.'\n",
    "## Group JPMorgan\n",
    "JPMorgan = fdic['name'].str.contains('J. P. Morgan|JPMorgan')\n",
    "fdic.loc[JPMorgan, 'Bank'] = 'JPMORGAN CHASE BANK, NATIONAL ASSOCIATION'\n",
    "## Group GMac\n",
    "GMac = fdic['name'].str.contains('GMAC')\n",
    "fdic.loc[GMac, 'Bank'] = 'GMAC MORTGAGE'\n",
    "## Group PNC\n",
    "PNC = fdic['name'].str.contains('PNC Bank')\n",
    "fdic.loc[PNC, 'Bank'] = 'PNC BANK, N.A.'\n",
    "## Group SunTrust\n",
    "SunTrust = fdic['name'].str.contains('SunTrust')\n",
    "fdic.loc[SunTrust, 'Bank'] = 'SUNTRUST MORTGAGE INC.'\n",
    "## Group AmTrust\n",
    "AmTrust = fdic['name'].str.contains('AmTrust|AMTRUST')\n",
    "fdic.loc[AmTrust, 'Bank'] = 'AMTRUST BANK'\n",
    "## Group Flagstar\n",
    "Flagstar = fdic['name'].str.contains('Flagstar')\n",
    "fdic.loc[Flagstar, 'Bank'] = 'FLAGSTAR CAPITAL MARKETS CORPORATION'\n",
    "## Group First Tennessee\n",
    "Tennessee = fdic['name'].str.contains('First Tennessee Bank')\n",
    "fdic.loc[Tennessee, 'Bank'] = 'FIRST TENNESSEE BANK NATIONAL ASSOCIATION'\n",
    "## Group Chase\n",
    "Chase = fdic['name'].str.contains('Chase')\n",
    "fdic.loc[Chase, 'Bank'] = 'CHASE HOME FINANCE'\n",
    "## Group IndyMac\n",
    "IndyMac = fdic['name'].str.contains('IndyMac')\n",
    "fdic.loc[IndyMac, 'Bank'] = 'FDIC, RECEIVER, INDYMAC FEDERAL BANK FSB'\n",
    "## Group small loan banks\n",
    "SmallLoans = fdic['name'].str.contains('Wells Fargo|HSBC|USAA|Third Federal')\n",
    "fdic.loc[SmallLoans, 'Bank'] = 'SMALL LOAN BANKS'\n",
    "## Group other banks\n",
    "fdic['Bank'] = np.where(fdic['Bank'].isnull(), 'OTHER', fdic['Bank'])\n",
    "\n",
    "# Drop name\n",
    "fdic = fdic.drop(labels=['name'], axis=1)\n",
    "\n",
    "# Convert to panel\n",
    "fdic = fdic.groupby(['Bank', 'repdte']).sum()\n",
    "fdic = fdic.reset_index(drop=False)\n",
    "\n",
    "# Fill monthly data\n",
    "fdic = fdic_on_month(fdic)\n",
    "fdic = fdic.groupby(['Bank', 'Original Date']).sum()\n",
    "\n",
    "print('Shape:', fdic.shape)\n",
    "display(fdic.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the by quarter totals for each measure\n",
    "quarter_totals = fdic.groupby(['Original Date']).sum()\n",
    "\n",
    "# compute the base quarter totals for each measure\n",
    "totals_base_qtr = quarter_totals.iloc[0,:]\n",
    "\n",
    "def janicki_prescott_norm(item):\n",
    "    \"\"\"\n",
    "    In order to make sure results are comparable across years, I follow \n",
    "    Janicki and Prescott (2006) and deflate and re-scale each measure of bank \n",
    "    size by dividing by banking sector totals relative to some base quarter. \n",
    "    Specifically, let :math:`S_{i,t}^{raw}` denote the raw size of bank :math:`i`\n",
    "    in year :math:`t` based on one of the six size measures detailed above. The \n",
    "    normalized size of bank :math:`i` relative to the base quarter is defined as\n",
    "    follows:\n",
    "             \n",
    "    .. math::\n",
    "    \n",
    "        S_{i,t}^{norm} = \\frac{S_{i,t}^{raw}}{\\sum_{j}S_{j,t}^{raw}}\\sum_{j}S_{i,base}^{raw}\n",
    "    \n",
    "    where :math:\\sum_{j}S_{j,t}^{raw}` is the banking sector total of some size \n",
    "    measure in year :math:`t` (i.e., total banking sector assets in year :math:`t`), \n",
    "    and :math:`\\sum_{j}S_{j,base}^{raw}` is the banking sector total of the same\n",
    "    size measure in the base quarter.\n",
    "    \n",
    "    \"\"\"\n",
    "    return (fdic[column] / quarter_totals[column]) * totals_base_qtr[column]\n",
    "\n",
    "# apply the Janicki and Prescott (2006) normalized size measure \n",
    "for column in fdic.columns:\n",
    "    fdic[column] = janicki_prescott_norm(column)\n",
    "\n",
    "# Period change\n",
    "fdic = fdic.reset_index(drop=False)\n",
    "for col in ['asset', 'lnlsnet', 'liab', 'dep', 'eqtot']:\n",
    "    fdic[[str(col + ' (Qtr)')]] = fdic[[col]].pct_change(4)\n",
    "    fdic[[str(col + ' (Yr)')]] = fdic[[col]].pct_change(12)\n",
    "\n",
    "# Drop total values\n",
    "fdic = fdic.drop(labels=['asset', 'lnlsnet', 'liab', 'dep', 'eqtot'], axis=1)\n",
    "\n",
    "# Regroup\n",
    "fdic = fdic.groupby(['Bank', 'Original Date']).sum()\n",
    "display(fdic.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "df = pd.merge(df, fdic, on=['Bank', 'Original Date'], how='left')\n",
    "    \n",
    "print('Shape:', df.shape)\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Data Missing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing\n",
    "(df.isna().sum() / df.shape[0] * 100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_store = open(\"..\\Data\\df.pickle\", \"wb\")\n",
    "pickle.dump(df, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporary chunks for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_open = open('..\\Data\\df.pickle', 'rb') \n",
    "df  = pickle.load(file_to_open) \n",
    "file_to_open.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=['Household Financial Obligations (Qtr)', 'Household Financial Obligations (Yr)', \n",
    "         'Consumer Debt Service Payment (Qtr)', 'Consumer Debt Service Payment (Yr)',\n",
    "         'National Home Price Index (Qtr)', 'National Home Price Index (Yr)',\n",
    "         'Mortgage Debt Service Payments (Qtr)', 'Mortgage Debt Service Payments (Yr)',\n",
    "         'Monthly Supply of Houses (Qtr)', 'Monthly Supply of Houses (Yr)',\n",
    "         'Vacant Housing Units for Sale (Qtr)', 'Vacant Housing Units for Sale (Yr)',\n",
    "         'Homeownership Rate (Qtr)', 'Homeownership Rate (Yr)', 'Vacant Housing Units for Rent (Qtr)',\n",
    "         'Vacant Housing Units for Rent (Yr)', 'Rental Vacancy Rate (Qtr)', 'Rental Vacancy Rate (Yr)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=['numemp', 'asset (Qtr)', 'asset (Yr)', 'lnlsnet (Qtr)', 'lnlsnet (Yr)', 'liab (Qtr)', 'liab (Yr)', 'dep (Qtr)', 'dep (Yr)', 'eqtot (Qtr)', 'eqtot (Yr)'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
