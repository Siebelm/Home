{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Bad Bank Behavior<br>Analyzing Bank Mortgage during the 2007 Housing Bubble</center>  \n",
    "\n",
    "<center>Michael Siebel</center>\n",
    "<center>August 2020</center>\n",
    "<br>\n",
    "\n",
    "## <center>Model Selection Script</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose  \n",
    "<br>\n",
    "\n",
    "> Runs a relative importance analysis called permutation importance to determine the most important features in each of the algorithms that will be modelled subsequently.  Features with low importance may be subject for removal from the model selection.\n",
    "\n",
    "> The permutation importance of a feature is calculated as follows. First, a baseline metric, defined by scoring, is evaluated on a (potentially different) dataset defined by the X. Next, a feature column from the validation set is permuted and the metric is evaluated again. The permutation importance is defined to be the difference between the baseline metric and metric from permutating the feature column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-ebbdb4776011>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Functions.ipynb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"display.max_columns\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m999\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_rows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m999\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfile_to_open\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..\\Data\\df.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "%run Functions.ipynb\n",
    "pd.set_option(\"display.max_columns\", 999)\n",
    "pd.set_option('display.max_rows', 999)\n",
    "\n",
    "file_to_open = open('..\\Data\\df.pickle', 'rb') \n",
    "df  = pickle.load(file_to_open) \n",
    "file_to_open.close()\n",
    "\n",
    "# Drop mergeID column\n",
    "df = df.drop(labels='Loan ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape:\\n', df.shape)\n",
    "print('\\nColumns:\\n', df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banks\n",
    "df['Bank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for One Hot encoding\n",
    "df_cat = df.select_dtypes(include=['object'])\n",
    "df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to drop\n",
    "dropvars = ['Original Date', 'File Year', 'File Quarter', 'Month', 'Region',\n",
    "            'Zip Code', 'Mortgage Insurance Type']  # 'Property State', \n",
    "\n",
    "# All data\n",
    "All_X = df.drop(labels=dropvars, axis=1)\n",
    "All_y = All_X['Foreclosed']\n",
    "All_X = All_X.drop(labels='Foreclosed', axis=1) \n",
    "\n",
    "# split dataset\n",
    "X_ignore, X_keep, y_ignore, y_keep = train_test_split(All_X, All_y, test_size = 0.2, \n",
    "                                                      stratify = All_y, random_state=2019)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_keep, y_keep, test_size = 0.5, \n",
    "                                                    stratify = y_keep, random_state=2019)\n",
    "\n",
    "# One hot encoding on remaining data\n",
    "X_train = onehotencoding(X_train)\n",
    "X_test = onehotencoding(X_test) \n",
    "X_cols = X_train.columns\n",
    "\n",
    "print(X_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "print(X_train.shape)\n",
    "\n",
    "# Missing\n",
    "print((X_train.isna().sum() / X_train.shape[0] * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute using KNN\n",
    "X_train = KNN_imputations(X_train, X_cols)\n",
    "\n",
    "# Missing\n",
    "X_train[['Household Financial Obligations (Qtr)', 'Household Financial Obligations (Yr)', \n",
    "         'Consumer Debt Service Payment (Qtr)', 'Consumer Debt Service Payment (Yr)',\n",
    "         'National Home Price Index (Qtr)', 'National Home Price Index (Yr)',\n",
    "         'Mortgage Debt Service Payments (Qtr)', 'Mortgage Debt Service Payments (Yr)',\n",
    "         'Monthly Supply of Houses (Qtr)', 'Monthly Supply of Houses (Yr)',\n",
    "         'Vacant Housing Units for Sale (Qtr)', 'Vacant Housing Units for Sale (Yr)',\n",
    "         'Homeownership Rate (Qtr)', 'Homeownership Rate (Yr)', 'Vacant Housing Units for Rent (Qtr)',\n",
    "         'Vacant Housing Units for Rent (Yr)', 'Rental Vacancy Rate (Qtr)', 'Rental Vacancy Rate (Yr)',\n",
    "         'numemp', 'asset (Qtr)',  'asset (Yr)', 'lnlsnet (Qtr)', 'lnlsnet (Yr)', 'liab (Qtr)', 'liab (Yr)',\n",
    "         'dep (Qtr)', 'dep (Yr)', 'eqtot (Qtr)', 'eqtot (Yr)']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing\n",
    "(X_train.isna().sum() / X_train.shape[0] * 100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative importance for balanced classes\n",
    "rel_imp_bal = {}\n",
    "for bank_str in np.unique(df['Bank']):\n",
    "    print(bank_str)\n",
    "    rel_imp_bal[bank_str] = relative_importance(X_train, y_train, bank_str, sample='bal')\n",
    "    print(rel_imp_bal[bank_str])\n",
    "    \n",
    "# Save final dictionary\n",
    "file_to_store = open(\"..\\Data\\rel_imp_bal.pickle\", \"wb\")\n",
    "pickle.dump(rel_imp_bal, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative importance for weighted classes\n",
    "rel_imp_wgt = {}\n",
    "for bank_str in np.unique(df['Bank']):\n",
    "    print(bank_str)\n",
    "    rel_imp_bal[bank_str] = relative_importance(X_train, y_train, bank_str, sample='wgt')\n",
    "    print(rel_imp_bal[bank_str])\n",
    "    \n",
    "# Save final dictionary\n",
    "file_to_store = open(\"..\\Data\\rel_imp_wgt.pickle\", \"wb\")\n",
    "pickle.dump(rel_imp_wgt, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative importance for unbalanced classes\n",
    "rel_imp_unbal = {}\n",
    "for bank_str in np.unique(df['Bank']):\n",
    "    print(bank_str)\n",
    "    rel_imp_unbal[bank_str] = relative_importance(X_train, y_train, bank_str, sample='none')\n",
    "    print(rel_imp_unbal[bank_str])\n",
    "    \n",
    "# Save final dictionary\n",
    "file_to_store = open(\"..\\Data\\rel_imp_unbal.pickle\", \"wb\")\n",
    "pickle.dump(rel_imp_unbal, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
