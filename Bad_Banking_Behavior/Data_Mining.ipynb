{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Bad Bank Behavior<br>Analyzing Bank Mortgage during the 2008 Housing Bubble</center>  \n",
    "\n",
    "<center>Michael Siebel</center>\n",
    "<center>December 2020</center>\n",
    "\n",
    "<br>\n",
    "    \n",
    "## <center>Data Mining Script</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals  \n",
    "<br>\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load functions\n",
    "%run Functions.ipynb\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Load data\n",
    "file_to_open = open('..\\Data\\Pickle\\df.pkl', 'rb') \n",
    "df = pickle.load(file_to_open) \n",
    "file_to_open.close()\n",
    "\n",
    "# Drop unused variables\n",
    "# Variables to drop\n",
    "dropvars = ['Year', 'Month', 'Region', 'Zero Balance Code', \n",
    "            'Mortgage Insurance Type', \n",
    "            'First Payment', 'Original Loan-to-Value (LTV)']\n",
    "df = df.drop(labels=dropvars, axis=1)\n",
    "df = df.filter(regex=r'^(?!Asset).*$')\n",
    "df = df.filter(regex=r'^(?!Liab).*$')\n",
    "df = df.filter(regex=r'^(?!Eqtot).*$')\n",
    "df = df.filter(regex=r'^(?!Dep).*$')\n",
    "df = df.dropna()\n",
    "\n",
    "file_to_open = open('..\\Data\\Pickle\\df_load.pkl', 'rb') \n",
    "df_load = pickle.load(file_to_open) \n",
    "file_to_open.close()\n",
    "\n",
    "# Variables to drop\n",
    "dropvars = ['Year', 'Month', 'Zero Balance Code', \n",
    "            'Mortgage Insurance Type', \n",
    "            'First Payment', 'Original Loan-to-Value (LTV)']\n",
    "df_load = df_load.drop(labels=dropvars, axis=1)\n",
    "df_load = df_load.dropna()\n",
    "\n",
    "# Convert Inf values to NA\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df_load = df_load.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Set up plots\n",
    "jtplot.style(ticks=True, grid=False)\n",
    "import plotly.io as pio\n",
    "from IPython.display import HTML\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foreclosure Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Year 2006')\n",
    "print(df_load.loc[df_load['File Year']==2006, 'Bank'].value_counts())\n",
    "print('\\n')\n",
    "\n",
    "print('Year 2007')\n",
    "print(df_load.loc[df_load['File Year']==2007, 'Bank'].value_counts())\n",
    "print('\\n')\n",
    "\n",
    "print('Year 2008')\n",
    "print(df_load.loc[df_load['File Year']==2008, 'Bank'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2006 and 2005, **FDIC, RECEIVER, INDYMAC FEDERAL BANK FSB** did not make enough loans to be displayed in the data.\n",
    "\n",
    "In 2005, **PNC BANK, N.A** did not make enough loans to be displayed in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Year 2006')\n",
    "display(Overall_Data(df = df_load, subset = \"df_load['File Year']==2006\").iloc[:,:2])\n",
    "print('\\n')\n",
    "\n",
    "print('Year 2007')\n",
    "display(Overall_Data(df = df_load, subset = \"df_load['File Year']==2007\").iloc[:,:2])\n",
    "print('\\n')\n",
    "\n",
    "print('Year 2008')\n",
    "display(Overall_Data(df = df_load, subset = \"df_load['File Year']==2008\").iloc[:,:2])\n",
    "print('\\n')\n",
    "\n",
    "print('All Years')\n",
    "display(Overall_Data(df = df_load, subset = \"df_load['File Year']>=2006\").iloc[:,:2])\n",
    "print('\\n')\n",
    "\n",
    "print('Isolating Other Loans (All Years)')\n",
    "subset = \"(df_load['File Year']>=2006) & (df_load['Bank']=='Other')\"\n",
    "display(Overall_Data(df = df_load, subset = subset).iloc[:,:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other**, smaller, banks constitute much fewer foreclosures (**5.9%**) compared to the big banks.  Removing them from the dataset should increase the proportion of foreclosures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop other banks\n",
    "df_load = df_load.loc[df_load['Bank'] != 'Other',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Year 2006')\n",
    "display(Overall_Data(df = df, subset = \"df['File Year']==2006\").iloc[:,:2])\n",
    "print('\\n')\n",
    "\n",
    "print('Year 2007')\n",
    "display(Overall_Data(df = df, subset = \"df['File Year']==2007\").iloc[:,:2])\n",
    "print('\\n')\n",
    "\n",
    "print('Year 2008')\n",
    "display(Overall_Data(df = df, subset = \"df['File Year']==2008\").iloc[:,:2])\n",
    "print('\\n')\n",
    "\n",
    "print('All Years')\n",
    "display(Overall_Data(df = df, subset = \"df['File Year']>=2006\").iloc[:,:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing **Other**, smaller, banks increased foreclosures from **7.7%** to **9.6%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quarter Version\n",
    "YrQtr = {}\n",
    "Qtr = ('Q1', 'Q2', 'Q3', 'Q4')\n",
    "Yr = range(2006,2009)\n",
    "i = 0\n",
    "for yr in Yr:\n",
    "    for qtr in Qtr:\n",
    "        YrQtr[i] = str(str(yr) + qtr)\n",
    "        i += 1\n",
    "        \n",
    "# Short Version\n",
    "YrShort = {}\n",
    "Yr = range(2006,2009)\n",
    "i = 0\n",
    "for yr in Yr:\n",
    "    YrShort[i] = str(yr)\n",
    "    i += 1\n",
    "       \n",
    "# Long Version\n",
    "df_YrLong = {}\n",
    "YrLong = {}\n",
    "Yr = range(2001,2009)\n",
    "i = 0\n",
    "for yr in Yr:\n",
    "    YrLong[i] = int(yr)\n",
    "    i += 1\n",
    "        \n",
    "print('Number in quarter time series', len(YrQtr))\n",
    "print('Number in short time series', len(YrShort))\n",
    "print('Number in long time series', len(YrLong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_yr = {}\n",
    "plot_df = pd.DataFrame(index=['Foreclosed (%)'], columns=YrLong.values())\n",
    "\n",
    "for j in range(len(YrLong)):\n",
    "    plot_yr[j] = Overall_Data(YrQtr = YrLong[j], df = df_load).iloc[1,0]\n",
    "    plot_df.iloc[:,j] = plot_yr[j]\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(16,10))\n",
    "plt.plot(plot_df.columns, plot_df.iloc[0,:], linewidth=5, alpha=1)\n",
    "\n",
    "ax.set_title('Foreclosure Rates\\n2001 - 2008')\n",
    "ax.axis(ymin=0, ymax=11)\n",
    "ax.set_ylabel('Foreclosures (%)')\n",
    "ax.set_xlabel('Year')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foreclosures\n",
    "Foreclosed = Overall_Data(df = df)\n",
    "\n",
    "# Graphing target variable\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "bars = Foreclosed.loc[:, 'Foreclosed (%)']\n",
    "bars.plot.barh(color='#ca2c92').invert_yaxis()\n",
    "\n",
    "plt.title(str('Overall Foreclosure Rate\\n2006 - 2008'), fontsize=16)\n",
    "plt.rcParams['font.size'] = '14'\n",
    "\n",
    "# Labels\n",
    "ls = bars.values\n",
    "xs = bars.values\n",
    "ys = np.array([0, 1])\n",
    "for x,y,l in zip(xs,ys,ls):\n",
    "    label = \"{:.1f}\".format(l)\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,y), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(3,0), # distance from text to points (x,y)\n",
    "                 color='white',\n",
    "                 ha='left') # horizontal alignment can be left, right or center\n",
    "\n",
    "plt.ylabel('Percentage')\n",
    "plt.xlim([0,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_frames = list()\n",
    "for i in range(len(YrQtr)):\n",
    "    \n",
    "    # Foreclosures\n",
    "    Foreclosed = Overall_Data(YrQtr = YrQtr[i], df = df)\n",
    "    \n",
    "    # Graphing target variable\n",
    "    fig = plt.figure(figsize=(15,4))\n",
    "    bars = Foreclosed.loc[:, 'Foreclosed (%)']\n",
    "    bars.plot.barh(color='#ca2c92').invert_yaxis()\n",
    "    plt.title(str('Foreclosures for ' + YrQtr[i]), fontsize=16)\n",
    "    plt.rcParams['font.size'] = '14'\n",
    "    \n",
    "    # Labels\n",
    "    ls = bars.values\n",
    "    xs = bars.values\n",
    "    ys = np.array([0, 1])\n",
    "    for x,y,l in zip(xs,ys,ls):\n",
    "        label = \"{:.1f}\".format(l)\n",
    "        plt.annotate(label, # this is the text\n",
    "                     (x,y), # this is the point to label\n",
    "                     textcoords=\"offset points\", # how to position the text\n",
    "                     xytext=(3,0), # distance from text to points (x,y)\n",
    "                     color='white',\n",
    "                     ha='left') # horizontal alignment can be left, right or center\n",
    "\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.xlim([0,100])\n",
    "    \n",
    "    plt.savefig(str(\"GIF_Frames/Foreclosures_\" + str(i) + \".png\"), transparent=False)\n",
    "    plt.close(fig)\n",
    "    gif = Image.open(str(\"GIF_Frames/Foreclosures_\" + str(i) + \".png\"))\n",
    "    gif_frames.append(gif)\n",
    "\n",
    "# Save GIF\n",
    "gif_frames[0].save('GIF_Frames/Foreclosures.gif', format='GIF', save_all=True, \n",
    "                   append_images=gif_frames[1:], optimize=True, duration=900, loop=0)\n",
    "# Display GIF\n",
    "HTML('<img src=\"GIF_Frames/Foreclosures.gif\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographical Representation of Foreclosures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State Foreclosures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = {}\n",
    "frames = list()\n",
    "gif_frames = list()\n",
    "\n",
    "for i in range(len(YrLong)):\n",
    "    # Foreclosures\n",
    "    State_Foreclosures = df_load.loc[df_load['File Year']==YrLong[i],:] \\\n",
    "                         .groupby(['Property State']).agg({'Foreclosed': 'mean'})*100\n",
    "    State_Foreclosures = State_Foreclosures.round(1)\n",
    "    \n",
    "    # Graph\n",
    "    fig[i] = go.Figure(data=go.Choropleth(\n",
    "        locations=State_Foreclosures.index, # Spatial coordinates\n",
    "        z = State_Foreclosures['Foreclosed'].astype(float), # Data to be color-coded\n",
    "        zmin = 0,\n",
    "        zmax = 30,\n",
    "        locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "        colorscale = px.colors.sequential.Purples[3:],\n",
    "        marker_line_color=px.colors.sequential.Purples[3],\n",
    "        colorbar_title = \"Forclosures (%)\"\n",
    "    ))\n",
    "    \n",
    "    fig[i].update_layout(\n",
    "        title_text = str(\"Forclosures by State, \" + str(YrLong[i])),\n",
    "        geo_scope='usa', # limite map scope to USA\n",
    "        margin={\"r\":0,\"l\":0,\"b\":0}\n",
    "    )\n",
    "    \n",
    "    pio.write_image(fig[i], str(\"GIF_Frames/State_Foreclosures_\" + str(YrLong[i]) + \".png\"))\n",
    "    gif = Image.open(str(\"GIF_Frames/State_Foreclosures_\" + str(YrLong[i]) + \".png\"))\n",
    "    gif_frames.append(gif)\n",
    "\n",
    "# Save GIF\n",
    "gif_frames[0].save('GIF_Frames/State_Foreclosures.gif', format='GIF', save_all=True, \n",
    "                   append_images=gif_frames[1:], optimize=True, duration=900, loop=0)\n",
    "# Display GIF\n",
    "HTML('<img src=\"GIF_Frames/State_Foreclosures.gif\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foreclosures by Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "    \n",
    "# Import county zipcode crosswalk\n",
    "crosswalk = pd.read_csv(\"..\\Data\\ZIP-COUNTY-FIPS_2017-06.csv\",\n",
    "                        header = 0)\n",
    "crosswalk = crosswalk.rename(columns={'ZIP': 'Zip Code', 'COUNTYNAME': 'County', 'STCOUNTYFP': 'FIPS'})\n",
    "crosswalk = crosswalk.loc[:, ['Zip Code', 'County', 'FIPS']]\n",
    "crosswalk['Zip 5'] = crosswalk['Zip Code']\n",
    "crosswalk['Zip Code'] = crosswalk['Zip Code'].astype(str)\n",
    "crosswalk['Zip Code'] = crosswalk['Zip Code'].str.slice(start=0, stop=-2)\n",
    "crosswalk['Zip Code'] = crosswalk['Zip Code'].str.ljust(3, '0')\n",
    "crosswalk['FIPS'] = crosswalk['FIPS'].astype(str)\n",
    "crosswalk['FIPS'] = crosswalk['FIPS'].str.rjust(5, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = {}\n",
    "frames = list()\n",
    "gif_frames = list()\n",
    "\n",
    "for i in range(len(YrLong)):\n",
    "    # Foreclosures\n",
    "    FIPS_Foreclosures = df_load.loc[df_load['File Year']==YrLong[i],:] \\\n",
    "                        .groupby(['Zip Code']).agg({'Foreclosed': 'mean'})*100\n",
    "    FIPS_Foreclosures = FIPS_Foreclosures.round(1)\n",
    "    FIPS_Foreclosures = FIPS_Foreclosures.reset_index()\n",
    "    FIPS_Foreclosures['Zip Code'] = FIPS_Foreclosures['Zip Code'].astype(int).astype(str)\n",
    "    FIPS_Foreclosures['Zip Code'] = FIPS_Foreclosures['Zip Code'].str.ljust(3, '0')\n",
    "    \n",
    "    # Merge\n",
    "    FIPS_Foreclosures = pd.merge(FIPS_Foreclosures, crosswalk, on='Zip Code', how='inner')\n",
    "    \n",
    "    # Remove Outliers\n",
    "    FIPS_Foreclosures = FIPS_Foreclosures.loc[FIPS_Foreclosures['Foreclosed']!=100, :]\n",
    "    FIPS_Foreclosures = FIPS_Foreclosures.loc[FIPS_Foreclosures['Foreclosed']!=50, :]\n",
    "    \n",
    "    # Graph\n",
    "    fig[i] = go.Figure(data=go.Choropleth(\n",
    "        locations = FIPS_Foreclosures['FIPS'], # Spatial coordinates\n",
    "        z = FIPS_Foreclosures['Foreclosed'].astype(float), # Data to be color-coded\n",
    "        zmin = 0,\n",
    "        zmax = 30,\n",
    "        locationmode = 'geojson-id', # set of locations match entries in `locations`\n",
    "        geojson = counties,\n",
    "        colorscale = px.colors.sequential.Blues[3:],\n",
    "        marker_line_color=px.colors.sequential.Blues[3], \n",
    "        colorbar_title = \"Forclosures (%)\"\n",
    "    ))\n",
    "    \n",
    "    fig[i].update_layout(\n",
    "        title_text = str(\"Forclosures by Zip Code, \" + str(YrLong[i])),\n",
    "        geo_scope='usa', # limite map scope to USA\n",
    "        margin={\"r\":0,\"l\":0,\"b\":0}\n",
    "    )\n",
    "    \n",
    "    pio.write_image(fig[i], str(\"GIF_Frames/Zip_Foreclosures_\" + str(YrLong[i]) + \".png\"))\n",
    "    gif = Image.open(str(\"GIF_Frames/Zip_Foreclosures_\" + str(YrLong[i]) + \".png\"))\n",
    "    gif_frames.append(gif)\n",
    "\n",
    "# Save GIF\n",
    "gif_frames[0].save('GIF_Frames/Zip_Foreclosures.gif', format='GIF', save_all=True, \n",
    "                   append_images=gif_frames[1:], optimize=True, duration=900, loop=0)\n",
    "# Display GIF\n",
    "HTML('<img src=\"GIF_Frames/Zip_Foreclosures.gif\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank represented\n",
    "Banks = Bank_Data(df = df)\n",
    "Banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feautures per Bank\n",
    "Banks = Bank_Data(df = df, allvars = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnk_size = Banks[['Bank (N)']].sort_values(by=['Bank (N)'])\n",
    "fig = plt.figure(figsize=[15,7])\n",
    "plt.rcParams['font.size'] = '16'\n",
    "plt.bar(bnk_size.index, bnk_size.loc[:,'Bank (N)'], color = '#002855')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Number of Loans by Bank\\n2006 - 2008')\n",
    "plt.xlabel('Large Lending Banks')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foreclosures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worst actor\n",
    "worst_actor = pd.DataFrame()\n",
    "for i in range(len(YrShort)):\n",
    "    print(YrShort[i])\n",
    "    Banks_short = Bank_Data(YrQtr = YrShort[i], df = df, rounding = 5)\n",
    "    tbl = search_Banks('Foreclosed (%)', df = Banks_short, func = max)\n",
    "    tbl['Foreclosed (%)'] = tbl['Foreclosed (%)'].round(1)\n",
    "    display(tbl)\n",
    "    tbl = tbl.reset_index()\n",
    "    tbl.index = [YrShort[i]]\n",
    "    worst_actor = pd.concat([worst_actor, tbl], axis = 0)\n",
    "    print('')\n",
    "\n",
    "print('Overall')\n",
    "Banks_short = Bank_Data(df = df, rounding = 5)\n",
    "tbl = search_Banks('Foreclosed (%)', df = Banks_short, func = max)\n",
    "tbl['Foreclosed (%)'] = tbl['Foreclosed (%)'].round(1)\n",
    "display(tbl)\n",
    "tbl = tbl.reset_index()\n",
    "tbl.index = ['Overall']\n",
    "worst_actor = pd.concat([worst_actor, tbl], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best actor\n",
    "best_actor = pd.DataFrame()\n",
    "for i in range(len(YrShort)):\n",
    "    print(YrShort[i])\n",
    "    Banks_short = Bank_Data(YrQtr = YrShort[i], df = df, rounding = 5)\n",
    "    tbl = search_Banks('Foreclosed (%)', df = Banks_short, func = min)\n",
    "    tbl['Foreclosed (%)'] = tbl['Foreclosed (%)'].round(1)\n",
    "    display(tbl)\n",
    "    tbl = tbl.reset_index()\n",
    "    tbl.index = [YrShort[i]]\n",
    "    best_actor = pd.concat([best_actor, tbl], axis = 0)\n",
    "    print('')\n",
    "\n",
    "print('Overall')\n",
    "Banks_short = Bank_Data(df = df, rounding = 5)\n",
    "tbl = search_Banks('Foreclosed (%)', df = Banks_short, func = min)\n",
    "tbl['Foreclosed (%)'] = tbl['Foreclosed (%)'].round(1)\n",
    "display(tbl)\n",
    "tbl = tbl.reset_index()\n",
    "tbl.index = ['Overall']\n",
    "best_actor = pd.concat([best_actor, tbl], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_best_tbl = pd.concat([worst_actor, best_actor], axis=1)\n",
    "header = [np.array(['Worst Actors','Worst Actors','Best Actors','Best Actors']), \n",
    "          np.array(worst_best_tbl.columns)] \n",
    "pd.DataFrame(worst_best_tbl.values, index = worst_best_tbl.index, columns = header )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foreclosures per Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "gif_frames = []\n",
    "plot_yr = {}\n",
    "plot_df = pd.DataFrame(index=Banks.index, columns=YrLong.values())\n",
    "\n",
    "# Mortgage Amount ($) line chart\n",
    "for j in range(len(YrLong)):\n",
    "    plot_yr[j] = pd.DataFrame(Bank_Data(YrQtr = YrLong[j], df = df_load).loc[:, 'Foreclosed (%)'])\n",
    "    plot_yr[j][plot_yr[j]==0] = np.nan\n",
    "    plot_yr[j] = plot_yr[j].rename(columns={'Foreclosed (%)': YrLong[j]})\n",
    "    plot_df.loc[:,YrLong[j]] = plot_yr[j].loc[:,YrLong[j]]\n",
    "\n",
    "plt.rcParams['figure.figsize']=(16,10)\n",
    "plt.rcParams['font.size'] = '16'\n",
    "plot_dfs = pd.DataFrame(index=Banks.index, columns=YrLong.values()).T\n",
    "for j in range(len(plot_dfs.columns)):\n",
    "    for i in range(len(plot_dfs.index)):\n",
    "        plot_dfs.iloc[:i+1,j] = plot_df.T.iloc[:i+1,j]\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(plot_dfs.index, plot_dfs, linewidth=5, alpha=1)\n",
    "        plt.gca().set_prop_cycle(None)\n",
    "        ax.plot(plot_df.T.index, plot_df.T, linewidth=2, alpha=0.33)\n",
    "\n",
    "        ax.set_title('Bank Foreclosure Rates\\n' + plot_dfs.columns[j] + ' ' + str(YrLong[i]))\n",
    "        plt.axis(ymin=0, ymax=13)\n",
    "        ax.set_ylabel('Foreclosures (%)')\n",
    "        ax.set_xlabel('Year of Lending')\n",
    "        ax.legend(plot_df.T.columns, loc='lower right', fontsize=12)\n",
    "        \n",
    "        plt.savefig(str(\"GIF_Frames/Bank_Foreclosures_Yr_\" + plot_dfs.columns[j] + '_' + str(YrLong[i]) + \".png\"), transparent=False)\n",
    "        plt.close(fig)\n",
    "        gif = Image.open(str(\"GIF_Frames/Bank_Foreclosures_Yr_\" + plot_dfs.columns[j] + '_' + str(YrLong[i]) + \".png\"))\n",
    "        gif_frames.append(gif)\n",
    "        \n",
    "# Save GIF\n",
    "gif_frames[0].save('GIF_Frames/Bank_Foreclosures_Yr.gif', format='GIF', save_all=True, \n",
    "                   append_images=gif_frames[1:], optimize=True, duration=200, loop=0)\n",
    "# Display GIF\n",
    "HTML('<img src=\"GIF_Frames/Bank_Foreclosures_Yr.gif\">')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Likely to Define Foreclosures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predicted probabilities\n",
    "## Improved assumptions\n",
    "improved = pickle.load(open(\"..\\Data\\Pickle\\pred_votes_improved.pkl\", \"rb\"))[0]\n",
    "improved_values = pickle.load(open(\"..\\Data\\Pickle\\pred_votes_improved.pkl\", \"rb\"))[1]\n",
    "best = pickle.load(open(\"..\\Data\\Pickle\\pred_votes_improved.pkl\", \"rb\"))[2]\n",
    "best_values = pickle.load(open(\"..\\Data\\Pickle\\pred_votes_improved.pkl\", \"rb\"))[3]\n",
    "\n",
    "## Weakened assumptions\n",
    "weakened = pickle.load(open(\"..\\Data\\Pickle\\pred_votes_weakened.pkl\", \"rb\"))[0]\n",
    "weakened_values = pickle.load(open(\"..\\Data\\Pickle\\pred_votes_weakened.pkl\", \"rb\"))[1]\n",
    "worst = pickle.load(open(\"..\\Data\\Pickle\\pred_votes_weakened.pkl\", \"rb\"))[2]\n",
    "worst_values = pickle.load(open(\"..\\Data\\Pickle\\pred_votes_weakened.pkl\", \"rb\"))[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_density('Credit Score', bins=None, l_xlim=300, r_xlim=850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_score = Bank_Data(df = df, allvars = True)[['Credit Score']]\n",
    "bank_rank_gph('Credit Score', df, credit_score, b_ylim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_worst_gph('Credit Score', df = credit_score, l_xlim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_worst_density('Credit Score', df, credit_score, bins=None, l_xlim=300, r_xlim=850)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_assumptions_tbl('Credit Score', improved, weakened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_gph('Credit Score', df = credit_score, proba = improved, proba_value = improved_values)\n",
    "\n",
    "predicted_gph('Credit Score', df = credit_score, proba = weakened, proba_value = weakened_values, \n",
    "              improved=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debt to Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_density('Original Debt to Income Ratio', bins=20, l_xlim=0, r_xlim=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti = Bank_Data(df = df, allvars = True)[['Original Debt to Income Ratio']]\n",
    "bank_rank_gph('Original Debt to Income Ratio', df, dti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_worst_gph('Original Debt to Income Ratio', df = dti, func = [min, max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_worst_density('Original Debt to Income Ratio', df, dti, func = [min, max], \n",
    "                   bins = 20, l_xlim=0, r_xlim=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_assumptions_tbl('Original Debt to Income Ratio', improved, weakened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_gph('Original Debt to Income Ratio', df = dti, proba = improved, proba_value = improved_values)\n",
    "\n",
    "predicted_gph('Original Debt to Income Ratio', df = dti, proba = weakened, proba_value = weakened_values, \n",
    "              improved=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Loan to Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_density('Original Combined Loan-to-Value (CLTV)', bins=None, l_xlim=0, r_xlim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cltv = Bank_Data(df = df, allvars = True)[['Original Combined Loan-to-Value (CLTV)']]\n",
    "bank_rank_gph('Original Combined Loan-to-Value (CLTV)', df, cltv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_worst_gph('Original Combined Loan-to-Value (CLTV)', df = cltv, func = [min, max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_worst_density('Original Combined Loan-to-Value (CLTV)', df, cltv, func = [min, max], \n",
    "                   bins=None, l_xlim=0, r_xlim=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_assumptions_tbl('Original Combined Loan-to-Value (CLTV)', improved, weakened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_gph('Original Combined Loan-to-Value (CLTV)', df = cltv, \n",
    "              proba = improved, proba_value = improved_values)\n",
    "\n",
    "predicted_gph('Original Combined Loan-to-Value (CLTV)', df = cltv, \n",
    "              proba = weakened, proba_value = weakened_values, improved=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median Household Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_density('Median Household Income', l_xlim=20000, r_xlim=110000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhi = Bank_Data(df = df, allvars = True)[['Median Household Income']]\n",
    "bank_rank_gph('Median Household Income', df, mhi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_worst_gph('Median Household Income', df = mhi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_worst_density('Median Household Income', df, mhi, l_xlim=20000, r_xlim=110000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_assumptions_tbl('Median Household Income', improved, weakened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_gph('Median Household Income', df = mhi, \n",
    "              proba = improved, proba_value = improved_values)\n",
    "\n",
    "predicted_gph('Median Household Income', df = mhi, \n",
    "              proba = weakened, proba_value = weakened_values, improved=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best and worst assumptions illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_assumptions_tbl('Median Household Income', best, worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_gph('Median Household Income', df = mhi, \n",
    "              proba = best, proba_value = best_values)\n",
    "\n",
    "predicted_gph('Median Household Income', df = mhi, \n",
    "              proba = worst, proba_value = worst_values, improved=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ['Loan Change (1 Year)', 'Loan Change (5 Years)']:\n",
    "    feature_density(v, l_xlim=-100000, r_xlim=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc1 = Bank_Data(df = df, allvars = True)[['Loan Change (1 Year)']]\n",
    "bank_rank_gph('Loan Change (1 Year)', df, lc1)\n",
    "\n",
    "lc5 = Bank_Data(df = df, allvars = True)[['Loan Change (5 Years)']]\n",
    "bank_rank_gph('Loan Change (5 Years)', df, lc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_worst_gph('Loan Change (1 Year)', df = lc1, func = [min, max])\n",
    "\n",
    "best_worst_gph('Loan Change (5 Years)', df = lc5, func = [min, max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_worst_density('Loan Change (1 Year)', df, lc1, func = [min, max], \n",
    "                           l_xlim=-100000, r_xlim=100000)\n",
    "\n",
    "best_worst_density('Loan Change (5 Years)', df, lc5, func = [min, max], \n",
    "                           l_xlim=-100000, r_xlim=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_assumptions_tbl('Loan Change (1 Year)', improved, weakened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_gph('Loan Change (1 Year)', df = lc1, \n",
    "              proba = improved, proba_value = improved_values)\n",
    "\n",
    "predicted_gph('Loan Change (1 Year)', df = lc1, \n",
    "              proba = weakened, proba_value = weakened_values, improved=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ['Lnlsnet (1 Yr)', 'Lnlsnet (5 Yr)']:\n",
    "        display(feature_density(v, hist=False, l_xlim=-300, r_xlim=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnl1 = Bank_Data(df = df, allvars = True)[['Lnlsnet (1 Yr)']]\n",
    "display(bank_rank_gph('Lnlsnet (1 Yr)', df, lnl1, b_ylim=-500, t_ylim=4000))\n",
    "\n",
    "lnl5 = Bank_Data(df = df, allvars = True)[['Lnlsnet (5 Yr)']]\n",
    "display(bank_rank_gph('Lnlsnet (5 Yr)', df, lnl5, b_ylim=-500, t_ylim=4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(best_worst_gph('Lnlsnet (1 Yr)', lnl1, func = [min, max], l_xlim=-500, r_xlim=4000))\n",
    "\n",
    "display(best_worst_gph('Lnlsnet (5 Yr)', lnl5, func = [min, max], l_xlim=-500, r_xlim=4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(best_worst_density('Lnlsnet (1 Yr)', df, lnl1, func = [min, max], \n",
    "                           hist=False, l_xlim=-300, r_xlim=1000))\n",
    "\n",
    "display(best_worst_density('Lnlsnet (5 Yr)', df, lnl5, func = [min, max], \n",
    "                           hist=False, l_xlim=-300, r_xlim=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_assumptions_tbl('Lnlsnet (1 Yr)', improved, weakened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_gph('Lnlsnet (1 Yr)', df = lnl1, \n",
    "              proba = improved, proba_value = improved_values)\n",
    "\n",
    "predicted_gph('Lnlsnet (1 Yr)', df = lnl1, \n",
    "              proba = weakened, proba_value = weakened_values, improved=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best and worst assumption illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_assumptions_tbl('Lnlsnet (1 Yr)', best, worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_gph('Lnlsnet (1 Yr)', df = lnl1, \n",
    "              proba = best, proba_value = best_values)\n",
    "\n",
    "predicted_gph('Lnlsnet (1 Yr)', df = lnl1, \n",
    "              proba = worst, proba_value = worst_values, improved=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
