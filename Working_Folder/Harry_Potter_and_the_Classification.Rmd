---
title: "Harry Potter NLP"
author: "Michael Siebel"
date: "`r date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    css: "../Rstyles.css" 
    code_folding: hide
    highlight: tango
    includes:
      in_header: "menu.html"
---

<br>

>  Model Ensembling and Classification for: <br>
>  Harry Potter and the Philosopher's Stone (1997) <br>
>  Harry Potter and the Chamber of Secrets (1998) <br>
>  Harry Potter and the Prisoner of Azkaban (1999) <br>
>  Harry Potter and the Goblet of Fire (2000) <br>
>  Harry Potter and the Order of the Phoenix (2003) <br>
>  Harry Potter and the Half-Blood Prince (2005) <br>
>  Harry Potter and the Deathly Hallows (2007)

# Bottom Line Up Front

I intend to answer the question:
<h6>"Which Harry Potter film is closest to its corresponding book?"</h6>

In this document, I built a model classifying portions of each books' text into the book that it belongs.  In the next, I will run film scripts through that model to determine how will it aligns with its corresponding book.

Classifying these books took 6 steps:

I) Define documents

   * Description: Create documents at the page-level
   * Purpose: Define portions of text that are small enough to provide many examples for the model but large enough to capture meaningful differences in text per book
   
II) Structure text for 4 models

   * Description: Build 4 document term matricies (DTM) using different NLP techniques
   * Purpose: Use multiple NLP techniques in order to take advantage of each of their strengths
   
III) Oversample

   * Description: Balance classes by oversampling from shorter pieces of text from training pages
   * Purpose: Enrich training data to improve predictions of shorter books
   
IV) Run 4 models

   * Description: Run 4 models independently with hyper-parameter tuning
   * Purpose: Optimize 4 models   

V) Perform stacked ensemble modeling

   * Description: Ensemble 4 bottom layer models with top layer model
   * Purpose: Take strengths of each model and minimize each model's weaknesses 

VI) Determine final model performance

   * Description: Test results of stacked model ensemble on testing data
   * Purpose: Ensure model process and outcome is generalizable

# Setup
```{r setup, results=FALSE, echo=TRUE, message=FALSE, comment=NA, warning=FALSE, tidy=TRUE} 
rm(list=ls())
gc()


library(pacman)
pacman::p_load(knitr, magrittr, dplyr, ggplot2, rvest, xgboost, sentimentSetsR, caret, textTinyR, text2vec, tm, tidytext, stringr, stringi, SnowballC, stopwords, kableExtra, corpus, glue, RColorBrewer, tidyr)
  
knitr::opts_chunk$set(echo=TRUE, message=FALSE, comment=NA, warning=FALSE, tidy=TRUE, results="hold", cache=FALSE, dpi=120)

# Custom functions
## Remove quotation marks
pasteNQ <- function(...) {
  output <- paste(...)
  noquote(output)
}
pasteNQ0 <- function(...) {
  output <- paste0(...)
  noquote(output)
}

## Chart Template
Grph_theme <- function() {
  palette <- brewer.pal("Greys", n=9)
  color.background = palette[2]
  color.grid.major = palette[3]
  color.axis.text = palette[6]
  color.axis.title = palette[7]
  color.title = palette[9]    
  theme_bw(base_size=9) + 
  theme(panel.background=element_rect(fill=color.background, color=color.background)) +
  theme(plot.background=element_rect(fill=color.background, color=color.background)) +
  theme(panel.border=element_rect(color=color.background)) +
  theme(panel.grid.major=element_line(color=color.grid.major,size=.25)) +
  theme(panel.grid.minor=element_blank()) +
  theme(axis.ticks=element_blank()) +
  theme(legend.position="none") +
  theme(legend.title=element_text(size=16,color='black')) +
  theme(legend.background = element_rect(fill=color.background)) +
  theme(legend.text = element_text(size=14,color='black')) +
  theme(strip.text.x = element_text(size=14,color='black',vjust=1)) +
  theme(plot.title=element_text(color=color.title, size=20, vjust=1.25)) +
  theme(axis.text.x=element_text(size=14,color='black')) +
  theme(axis.text.y=element_text(size=14,color='black')) +
  theme(axis.title.x=element_text(size=16,color='black', vjust=0)) +
  theme(axis.title.y=element_text(size=16,color='black', vjust=1.25)) +
  theme(plot.margin = unit(c(0.35, 0.2, 0.3, 0.35), "cm"))
}

## Chart Template Facet Wrap
Grph_theme_facet <- function() {
  palette <- brewer.pal("Greys", n=9)
  color.background = palette[2]
  color.grid.major = palette[3]
  color.axis.text = palette[6]
  color.axis.title = palette[7]
  color.title = palette[9]    
  theme_bw(base_size=8) + 
  theme(panel.background=element_rect(fill=color.background, color=color.background)) +
  theme(plot.background=element_rect(fill=color.background, color=color.background)) +
  theme(panel.border=element_rect(color=color.background)) +
  theme(panel.grid.major=element_line(color=color.grid.major,size=.25)) +
  theme(panel.grid.minor=element_blank()) +
  theme(axis.ticks=element_blank()) +
  theme(legend.position="none") +
  theme(legend.title=element_text(size=11,color='black')) +
  theme(legend.background = element_rect(fill=color.background)) +
  theme(legend.text = element_text(size=9,color='black')) +
  theme(strip.text.x = element_text(size=9,color='black',vjust=1)) +
  theme(plot.title=element_text(color=color.title, size=20, vjust=1.25)) +
  theme(axis.text.x=element_text(size=9,color='black')) +
  theme(axis.text.y=element_text(size=9,color='black')) +
  theme(axis.title.x=element_text(size=10,color='black', vjust=0)) +
  theme(axis.title.y=element_text(size=10,color='black', vjust=1.25)) +
  theme(plot.margin = unit(c(0.35, 0.2, 0.3, 0.35), "cm"))
}

## Clean Corpus
basicclean <- function(rawtext, contractions = TRUE) {
  
  # Set to lowercase
  rawtext <- tolower(rawtext)

  # Fix apostorphe
  rawtext <- gsub("â€™", "'", rawtext)

  # Remove contractions
  fix_contractions <- function(rawtext) {
    rawtext <- gsub("will not", "won't", rawtext)
    rawtext <- gsub("can't", "cannot", rawtext)
    rawtext <- gsub("can not", "cannot", rawtext)
    rawtext <- gsub("shall not", "shant", rawtext)
    rawtext <- gsub("n't", " not", rawtext)
    rawtext <- gsub("'ll", " will", rawtext)
    rawtext <- gsub("'re", " are", rawtext)
    rawtext <- gsub("'ve", " have", rawtext)
    rawtext <- gsub("'m", " am", rawtext)
    rawtext <- gsub("'d", " would", rawtext)
    rawtext <- gsub("'ld", " would", rawtext)
    rawtext <- gsub("'ld", " would", rawtext)
    rawtext <- gsub("'s", "", rawtext)
    return(rawtext)
  }
  if (contractions==TRUE) {
    rawtext <- fix_contractions(rawtext)
  }
  
  # Strip whitespace
  rawtext <- stripWhitespace(rawtext)

  return(rawtext)
}

# Remove stop words
removestopwords <- function(rawtext, remove=NULL, retain=NULL) {

  # Remove stop words
  stopwords_custom <- stopwords::stopwords("en", source = "snowball")
  stopwords_custom <- c(stopwords_custom, remove)
  stopwords_retain <- retain
  stopwords_custom <- stopwords_custom[!stopwords_custom %in% stopwords_retain]
  rawtext <- removeWords(rawtext, stopwords_custom)

  return(rawtext)
}

## Word Stemming
wordstem <- function(rawtext) {
  # Stemming words
  rawtext <- stemDocument(rawtext)

  return(rawtext)
}

## Remove Non-Alpha
removenonalpha <- function(rawtext) {
  # Remove puncutation, numbers, and other none characters
  rawtext <- removePunctuation(rawtext)
  rawtext <- removeNumbers(rawtext)
  rawtext <- gsub("[^[:alnum:]///' ]", "", rawtext)
  rawtext <- gsub("[']", "", rawtext)

  return(rawtext)
}
```

# I) Define Documents
**Description:** Create documents at the page-level
**Purpose:** Define portions of text that are small enough to provide many examples for the model but large enough to capture meaningful differences in text per book
   
* Page is defined as 250 words
* Series has 4,347 pages
* Create paragraph-level documents and link to page ID for later oversampling

```{r}
setwd("C:/Users/siebe/Documents/07_Books/Harry Potter/")

titles <- c("1 Philosopher's Stone", "2 Chamber of Secrets", "3 Prisoner of Azkaban",
            "4 Goblet of Fire", "5 Order of the Phoenix", "6 Half-Blood Prince",
            "7 Deathly Hallows")
html <- c("Harry_Potter_and_the_Philosophers_Stone.html",
          "Harry_Potter_and_the_Chamber_of_Secrets.html",
          "Harry_Potter_and_the_Prisoner_of_Azkaban.html",
          "Harry_Potter_and_the_Goblet_of_Fire.html",
          "Harry_Potter_and_the_Order_of_the_Phoenix.html",
          "Harry_Potter_and_the_Half-Blood_Prince.html",
          "Harry_Potter_and_the_Deathly_Hallows.html")

books <- tibble(Text=as.character(), Book=as.character())
para3 <- tibble(Text=as.character(), Book=as.character())
para1 <- tibble(Text=as.character(), Book=as.character())

for (i in 1:7) {  
  rawtext <- read_html(html[i])%>%
      html_nodes(xpath = '/html/body/p') %>%
          html_text(trim = TRUE)
  
  wordcount <- sapply(strsplit(rawtext, " "), length)
  paragraph <- rawtext #[wordcount >= 3]

  # Book Level Documents
  books <- rbind(books,
                 tibble(Text = str_c(paragraph, 
                                         collapse = " "),
                            Book = titles[i]
                            )
           )

  # Parapraph
  para1 <- rbind(para1,
                 tibble(Text = paragraph, Book = titles[i]))

  # Paragraph Level Documents
  triplet <- do.call(rbind, 
                     lapply(seq(1, length(paragraph), by = 3),
                          function(x) 
                                  tibble(Text = str_c(paragraph[x:(x+2)], 
                                                          collapse = " "),
                                             Book = titles[i]
                                             )
                          )
                   )
  para3 <- rbind(para3, triplet)
}

# Page Level Documents
pages <- books %>%
  unnest_tokens(Text, Text, 
                token = "regex", pattern = "[[:space:]]",
                to_lower = F) %>%
  group_by(Book, Page = dplyr::row_number() %/% 250) %>%
  dplyr::summarize(Text = stringr::str_c(Text, collapse = " ")) %>%
  mutate(Page = dplyr::row_number()) %>%
  ungroup()
## Wordcount
pages$Wordcount <- sapply(strsplit(pages$Text %>% as.character(), " "), length)
## Word IDs
s <- data.frame()
for(j in titles) {
  t <- pages[pages$Book==j, ]
  t$Word_Start <- NA
  t$Word_Start[1] <- 1
  t$Word_End <- NA
  t$Word_End[1] <- t$Wordcount[1]
  for(i in 2:nrow(t)) {
    t$Word_Start[i] <- t$Word_End[i-1] + 1
    t$Word_End[i] <- t$Word_Start[i] + t$Wordcount[i]
  }
  s <- rbind(s, t)
}
pages <- dplyr::left_join(pages, s)

# Paragraph Level Documents
# Add Page Numbers
page_nums <- function(df) {
  ## Drop missing
  df <- df[!is.na(df$Text), ]
  ## Paragraph ID
  df$Para_ID <- row.names(df) %>% as.numeric()
  ## Wordcount
  df$Wordcount <- sapply(strsplit(df$Text %>% as.character(), " "), length)
  ## Word IDs
  s <- data.frame()
  for(j in titles) {
    t <- df[df$Book==j, ]
    t$Word_Start <- NA
    t$Word_Start[1] <- 1
    t$Word_End <- NA
    t$Word_End[1] <- t$Wordcount[1]
    for(i in 2:nrow(t)) {
      t$Word_Start[i] <- t$Word_End[i-1] + 1
      t$Word_End[i] <- t$Word_Start[i] + t$Wordcount[i]
    }
    s <- rbind(s, t)
  }
  df <- dplyr::left_join(df, s)
  
  # Page ID
  match_page <- function(j) {
    t1 <- df[df$Book==j, c("Para_ID", "Word_Start", "Word_End")]
    t2 <- pages[pages$Book==j, c("Page", "Word_Start", "Word_End")]
    
    t1$Page <- NA
    for(i1 in 1:nrow(t1)) {
        for(i2 in nrow(t2):1) {
        t1$Page[i1] <- ifelse((t1$Word_Start[i1] >= t2$Word_Start[i2]) & 
                              (t1$Word_Start[i1] <  t2$Word_End[i2]) & 
                              (t1$Word_End[i1] <= t2$Word_End[i2]+20),
                               t2$Page[i2],
                               t1$Page[i1])
      }
    }
    return(t1)
  }
  
  # Parallel
  pacman::p_load(future.apply)
  plan(multiprocess)
  s <- future_lapply(titles, match_page)
  s <- do.call("rbind", s)
  df <- dplyr::left_join(df, s)
  
  return(df)
}
para3 <- page_nums(para3)
para1 <- page_nums(para1)

# Remove Word IDs
pages <- pages[ , c("Text", "Book", "Wordcount", "Page")]
para3 <- para3[ , c("Text", "Book", "Wordcount", "Page")]
para1 <- para1[ , c("Text", "Book", "Wordcount", "Page")]

# Place books in chronolgical order
books$Book <- factor(books$Book, levels=titles)
para3$Book <- factor(para3$Book, levels=titles)
para1$Book <- factor(para1$Book, levels=titles)
pages$Book <- factor(pages$Book, levels=titles)
```

For this sentiment analysis, I want to grab the text around certain characters. Chapters are too much text as they can contain multiple story points, and sentences are too little text as they likely contain little contextual information.  

## Page Level Variation

Paragraph level analysis has the advantage of grouping text by logical beginnings and endings.  Alternatively, page level analysis often groups text by the beginning and ending in half-sentence, mid-paragraph.

However, page level analysis has the advantage of not containing any variation in document length; all documents are a standard 250 words.

Given these advantages and disadvantages, I prioritized paragraph level analysis by using all paragraph triplets in the Series.  I then appended (code later) random samples of page level documents inversely proportionaly to the amount of paragraph triplets in each book.  In other words, I balanced the classes, ensuring each book contained the same number of documents, by adding many page level documents to the shorter books and fewer page level documents to the longer books.

## Paragraph Level Variation

In addition, I take paragraphs for oversampling purposes.  However, paragraphs can be single sentences as in the case of two characters switch dialogue.  Therefore, I take paragraph triplets: three paragraphs containing three or more words.

I start checking for normal (or "normal-ish") distributions of words per paragraph triplet to make sure there is some consistency in document length.  The word distributions appear to approximate a normal distribution, although with a non-trivial right tail.  In addition, the word distributions are similar across books, making it a comparable level of analysis.

```{r}
# Remove Text
CleanText_p3 <- basicclean(para3$Text)
CleanText_p1 <- basicclean(para1$Text)
CleanText_w250 <- basicclean(pages$Text)

# Summary Statistics
pasteNQ0("Average Amount of Words per Paragraph Triplet")
summary(para3$Wordcount)

# Graph distribution of words all
ggplot(para3, aes(Wordcount, fill=I("#7F0909"))) + 
  geom_histogram() + 
  stat_bin(bins = 100) +
  Grph_theme_facet() +
  ylab('Frequency') + xlab('Count of Words') + 
  ggtitle('Words per Paragraph Triplet')

# Graph with book fill
ggplot(para3, aes(Wordcount, fill=Book)) + 
  geom_area(stat = "bin") + 
  scale_fill_manual(values = c("#946B2D", "#0D6217", "#000A90", 
                                 "#AAAAAA", "#000000", "#7F0909", "#FFC500")) +
  Grph_theme_facet() +
  ylab('Frequency') + xlab('Count of Words') + 
  ggtitle('Words per Paragraph Triplet') + 
  theme(legend.text = element_text(size=8,color='black')) +
  theme(legend.position="bottom")
```


# II) Structure Text for Four Models
**Description:** Build 4 document term matricies (DTM) using different NLP techniques
**Purpose:** Use multiple NLP techniques in order to take advantage of each of their strengths
   
## Sentiment Model

### Sentiment Scores
```{r}
# Sentiment Scores
average <- function(x) {
  pos <- sum(x[x>0], na.rm = T)
  neg <- sum(x[x<0], na.rm = T) %>% abs()
  neu <- length(x[x==0])
  bal <- ( (pos-neg)/(pos+neg) )*100
  y <- ifelse(is.nan(bal),0,bal %>% as.numeric())
  return(y)
}

pages$Sentiment <- sapply(CleanText_w250, 
                          function(x) getSentiment(x, dictionary = "vader", 
                                                   score.type = average))
para3$Sentiment <- sapply(CleanText_p3, 
                          function(x) getSentiment(x, dictionary = "vader", 
                                                   score.type = average)) 
para1$Sentiment <- sapply(CleanText_p1, 
                          function(x) getSentiment(x, dictionary = "vader", 
                                                   score.type = average)) 
```


### Animated Writing
```{r, include=F}
# count exclamation marks
pages$Exclamation_Mark <- str_count(pages$Text, "[!]") %>%
                ifelse(is.na(.),0,.)
para3$Exclamation_Mark <- str_count(para3$Text, "[!]") %>%
                ifelse(is.na(.),0,.)
para1$Exclamation_Mark <- str_count(para1$Text, "[!]") %>%
                ifelse(is.na(.),0,.)

# count question marks
pages$Question_Mark <- str_count(pages$Text, "[?]") %>%
                ifelse(is.na(.),0,.)
para3$Question_Mark <- str_count(para3$Text, "[?]") %>%
                ifelse(is.na(.),0,.)
para1$Question_Mark <- str_count(para1$Text, "[?]") %>%
                ifelse(is.na(.),0,.)

# count elipse
# pages$Elipsis <- str_count(pages$Text, "[.]{3}") %>%
#                 ifelse(is.na(.),0,.)
# para3$Elipses <- str_count(para3$Text, "...") %>%
#                 ifelse(is.na(.),0,.)
# para1$Elipses <- str_count(para1$Text, "...") %>%
#                 ifelse(is.na(.),0,.)
```


### Lead Characters
```{r}
trio <- c("harry", "ron", "hermione")
heroes <- c("lily","james","hagrid","dumbledore","sirius","lupin","moody","slughorn","dobby","cedric","luna","tonks","mcgonagall","ginny","order of the phoenix","neville")
villians <- c("voldemort","nagini","snape","draco","lucius","umbridge","pettigrew","dementor","dementors","greyback","bellatrix","quirrell","riddle","death eaters","aragog","basilisk","dudley","vernon","petunia")

Sentiment <- c(trio, heroes, villians)

# Page Level
for(string in Sentiment) {
  findstr <- paste0("\\b",string,"\\b")
  assign( string, ifelse(grepl(findstr,CleanText_w250),1,0) )
}
pages <- cbind(pages, sapply( Sentiment, get ) * pages$Sentiment )

# Paragraph Level
for(string in Sentiment) {
  findstr <- paste0("\\b",string,"\\b")
  assign( string, ifelse(grepl(findstr,CleanText_p3),1,0) )
}
para3 <- cbind(para3, sapply( Sentiment, get ) * para3$Sentiment )

for(string in Sentiment) {
  findstr <- paste0("\\b",string,"\\b")
  assign( string, ifelse(grepl(findstr,CleanText_p1),1,0) )
}
para1 <- cbind(para1, sapply( Sentiment, get ) * para1$Sentiment )
```


## Bag of Words
```{r}
# Function
dtm_bow <- function(train_text, test_text, val_text) {
  set.seed(2020)
  
  train_text_cleaned <- train_text %>%
                        basicclean() %>%
                        removestopwords() %>%
                        wordstem() %>%
                        removenonalpha()
  test_text_cleaned <- test_text %>%
                       basicclean() %>%
                       removestopwords() %>%
                       wordstem() %>%
                       removenonalpha()
  
  #Train
  ## IDs
  ids <- 1:length(train_text_cleaned)
  
  ## tokenize
  it_train <- itoken(train_text_cleaned, 
  				     ids = ids, 
  				     progressbar = FALSE) 
  
  ## ngrams
  vocab <- create_vocabulary(it_train, c(1,1)) 
  vocab <- prune_vocabulary(vocab, doc_proportion_min = 0.01)
  
  vectorizer <- vocab_vectorizer(vocab)
  
  ## create dtm
  dtm_train <- create_dtm(it_train, vectorizer, type="dgCMatrix")

  # Test
  ## IDs
  ids <- 1:length(test_text_cleaned)

  ## tokenize
  it_test <- itoken(test_text_cleaned, 
  				    ids = ids, 
  				    progressbar = FALSE) 
  
  # create dtm
  dtm_test <- create_dtm(it_test, vectorizer, type="dgCMatrix")
  
  if (val_text != "") {
    # Validate
    val_text_cleaned <- val_text %>%
                       basicclean() %>%
                       removestopwords() %>%
                       wordstem() %>%
                       removenonalpha()
      
    ## IDs
    ids <- 1:length(val_text_cleaned)
  
    ## tokenize
    it_val <- itoken(val_text_cleaned, 
    				    ids = ids, 
    				    progressbar = FALSE) 
    
    # create dtm
    dtm_val <- create_dtm(it_val, vectorizer, type="dgCMatrix")
  }
  
  return(list(dtm_train, dtm_test, dtm_val))
}
```


## Word Embeddings
```{r}
# Function
dtm_we <- function(train_text, test_text, top_text, doc2vec = "sum_sqrt") {
  set.seed(20)
  
  # Simple clean
  train_text_cleaned <- train_text %>%
                        basicclean(contractions = F) 
  test_text_cleaned <- test_text %>%
                       basicclean(contractions = F)
  
  # Tokenize
  tokens <- word_tokenizer(train_text)

  # create dtm
  dtm_train <- textTinyR::Doc2Vec$new(token_list = tokens, 
  							          word_vector_FILE = "glove.42B.300d.vec",
  							          copy_data = FALSE) 
  
	if (doc2vec == "sum_sqrt") {							
		dtm_train <- dtm_train$doc2vec_methods(method = "sum_sqrt", 
		                                       threads = 8)
	} else if (doc2vec == "min_max_norm") {
		dtm_train <- dtm_train$doc2vec_methods(method = "min_max_norm", 
		                                       threads = 8)
	} else if (doc2vec == "idf") {
	  ## IDs
    ids <- 1:length(train_text)
    ## tokenize
    it_train <- itoken(train_text_cleaned, 
    				   ids = ids, 
    				   progressbar = FALSE) 
    ## ngrams
    vocab <- create_vocabulary(it_train, c(1,1)) 
    ## IDF
		utl <- textTinyR::sparse_term_matrix$new(vector_data = unlist(vocab), 
		                                         file_data = NULL,
												 document_term_matrix = TRUE)
		tm <- utl$Term_Matrix(verbose=F)
		gl_term_w <- utl$global_term_weights()
		dtm_train <- dtm_train$doc2vec_methods(method = "idf", 
		                                       global_term_weights = gl_term_w, threads = 8)	
	}  
  
  
  # Test
  ## Tokenize
  tokens <- word_tokenizer(test_text)
  
  ## create dtm
  dtm_test <- textTinyR::Doc2Vec$new(token_list = tokens, 
  							         word_vector_FILE = "glove.42B.300d.vec",
  							         copy_data = FALSE) 
  
	if (doc2vec == "sum_sqrt") {							
		dtm_test <- dtm_test$doc2vec_methods(method = "sum_sqrt", 
		                                     threads = 8)
	} else if (doc2vec == "min_max_norm") {
		dtm_test <- dtm_test$doc2vec_methods(method = "min_max_norm", 
		                                     threads = 8)
	} else if (doc2vec == "idf") {
	  ### IDs
    ids <- 1:length(test_text)
    ### tokenize
    it_test <- itoken(test_text_cleaned, 
    				  ids = ids, 
    				  progressbar = FALSE) 
    ### ngrams
    vocab <- create_vocabulary(it_test, c(1,1))
    ### IDF
		utl <- textTinyR::sparse_term_matrix$new(vector_data = unlist(vocab), 
		                                         file_data = NULL,
												 document_term_matrix = TRUE)
		tm <- utl$Term_Matrix(verbose=F)
		gl_term_w <- utl$global_term_weights()
		dtm_test <- dtm_test$doc2vec_methods(method = "idf", 
                                             global_term_weights = gl_term_w, 
                                             threads = 8)
	}
  
  # Top layer
  if (top_text != "") {
    top_text_cleaned <- top_text %>%
                       basicclean(contractions = F)
    
    ## Tokenize
    tokens <- word_tokenizer(top_text)
    
    ## create dtm
    dtm_top <- textTinyR::Doc2Vec$new(token_list = tokens, 
    							         word_vector_FILE = "glove.42B.300d.vec",
    							         copy_data = FALSE) 
    
	  if (doc2vec == "sum_sqrt") {							
	  	dtm_top <- dtm_top$doc2vec_methods(method = "sum_sqrt", 
	  	                                     threads = 8)
	  } else if (doc2vec == "min_max_norm") {
	  	dtm_top <- dtm_top$doc2vec_methods(method = "min_max_norm", 
	  	                                     threads = 8)
	  } else if (doc2vec == "idf") {
	    ### IDs
      ids <- 1:length(top_text)
      ### tokenize
      it_top <- itoken(top_text_cleaned, 
      				  ids = ids, 
      				  progressbar = FALSE) 
      ### ngrams
      vocab <- create_vocabulary(it_top, c(1,1))
      ### IDF
	  	utl <- textTinyR::sparse_term_matrix$new(vector_data = unlist(vocab), 
	  	                                         file_data = NULL,
	  											 document_term_matrix = TRUE)
	  	tm <- utl$Term_Matrix(verbose=F)
	  	gl_term_w <- utl$global_term_weights()
	  	dtm_top <- dtm_top$doc2vec_methods(method = "idf", 
                                         global_term_weights = gl_term_w,   
                                         threads = 8)
	  }  
  }
  
  return(list(dtm_train, dtm_test, dtm_top))
}
```


# III) Oversample
**Description:** Balance classes by oversampling from shorter pieces of text from training pages
**Purpose:** Enrich training data to improve predictions of shorter books
   
* Double training size and balance classes in training data
  - Doubled training size helps reduce overpredictions of shorter books caused by oversampling
* Randomly sample single and triple paragraphs from training pages
  - Use different samples per model by setting different seeds per sample

## Data Imbalances in Training Data
```{r}
set.seed(2020)
train_index <- sample(nrow(pages),nrow(pages)*0.80)

train <- pages[train_index, ]
test  <- pages[-train_index, ]

# Currently balance
pasteNQ("Current Balance")
table(train$Book)

# sort Book freqs by chronological order
docs <- table(train$Book) %>%
        as.data.frame()

# Define upsample scalars
upsample_n <- max(docs$Freq) - docs$Freq
upsample_n <- floor((upsample_n * 2 + docs$Freq) / 3)
upsample_para1 <- upsample_n * 2
upsample_para3 <- upsample_n

# Should all be the same number
cat("\n")
pasteNQ("Target Balance:")
upsample_para1 + upsample_para3 + docs$Freq
train_nrow <- sum(upsample_n * 3 + docs$Freq)
```

## Upsampling Functions
```{r}
upsample <- function(df, upsample_n) {
  # Remove short docs
  df <- df[df$Wordcount > 20, ]
  
  # Separate pages corpus into separate objects by Book title
  for(i in 1:7) {
      assign(paste0("page_", i),
             train[train$Book==titles[i],] %>%
             tidyr::drop_na())
    
      assign(paste0("para_", i),
             df[df$Book==titles[i],] %>%
             tidyr::drop_na())
  }
  
  # Upsample from single paragraphs by taking random sample 
  # w/o replacement of upsample scalars
  upsamples <- data.frame()
  for (i in 1:7) {
    r <- get(paste0("page_", i))
    t <- get(paste0("para_", i))
    upsamples <- rbind(upsamples, (
                       t[sample(nrow(t[t$Page %in% r$Page, ]), 
                                size = upsample_n[i]), ]
                       )
    )
    t <- NULL
  }
  
  df <- upsamples
  
  return(df)
}

upsample_train <- function() {
  para3_df <- upsample(para3, upsample_para3)
  para1_df <- upsample(para1, upsample_para1)
  train <- rbind(train, para3_df)
  train <- rbind(train, para1_df)
  
  return(train)
}
```


## Create Four Datasets
```{r}
# Target Variables
target_test  <- test[ , "Book"] %>% 
                make.names() 

# Dataframe for results
results_test  <- data.frame(Target = target_test)
num_test  <- as.factor(target_test) %>% as.numeric - 1

# Top layer train
set.seed(2020)
up_top_train <- upsample_train()
top_train_target <- up_top_train$Book
top_num_train <- as.factor(top_train_target) %>% as.numeric() - 1

# Sentiment Model
## Bottom Layer
set.seed(20)
up_train <- upsample_train()
sent_train_target <- up_train$Book
sent_train <- select(up_train, 
                     -c("Text", "Book", "Page", "Wordcount"))
sent_test  <- select(test, 
                     -c("Text", "Book", "Page", "Wordcount"))
## Top Layer
sent_top_train <- select(up_top_train, 
                         -c("Text", "Book", "Page", "Wordcount"))

# Bag of Words (TF) Model
## Bottom Layer
set.seed(21)
up_train <- upsample_train()
bow_train_target <- up_train$Book
bow_dtm <- dtm_bow(up_train$Text, test$Text, up_top_train$Text)
bow_train <- bow_dtm[[1]]
bow_test  <- bow_dtm[[2]]
## Top Layer
bow_top_train <- bow_dtm[[3]]

# Bag of Words (TF-IDF) Model
## Bottom Layer
set.seed(22)
up_train <- upsample_train()
bowtfidf_train_target <- up_train$Book
bowtfidf_dtm <- dtm_bow(up_train$Text, test$Text, up_top_train$Text)
bowtfidf_train <- bowtfidf_dtm[[1]]
bowtfidf_test  <- bowtfidf_dtm[[2]]
tfidf <- TfIdf$new()
bowtfidf_train <- fit_transform(bowtfidf_train, tfidf)
bowtfidf_test  <- transform(bowtfidf_test, tfidf)
## Top Layer
bowtfidf_top_train <- bowtfidf_dtm[[3]]
bowtfidf_top_train <- transform(bowtfidf_top_train, tfidf)

# Word Embeddings (Sum-SQRT) Model
## Bottom Layer
set.seed(23)
up_train <- upsample_train()
we_ss_train_target <- up_train$Book
we_ss_dtm <- dtm_we(up_train$Text, test$Text, 
                    up_top_train$Text, doc2vec = "sum_sqrt")
we_ss_train <- we_ss_dtm[[1]]
we_ss_test  <- we_ss_dtm[[2]]
## Top Layer
we_ss_top_train <- we_ss_dtm[[3]]


save(pages, para1, para3, target_test, train, test, train_nrow,
     sent_train_target, sent_train, sent_test, sent_top_train,
     bow_train_target, bow_train, bow_test, bow_top_train,
     bowtfidf_train_target, bowtfidf_train, bowtfidf_test, tfidf, bowtfidf_top_train,
     we_ss_train_target, we_ss_train, we_ss_test, we_ss_top_train,
     top_train_target, top_num_train, up_top_train,
     results_test, num_test, 
     upsample, upsample_train,
     file = "Harry_Potter_and_the_Classification.RData")
```


# IV) Run Four Models
**Description:** Run 4 models independently with hyper-parameter tuning
**Purpose:** Optimize 4 models

* Test 25 different versions of hyper-parameters on 4-fold cross validation
* Take best hyper-parameters and rerun on all training data 
* Repeat for each model

```{r}
load("Harry_Potter_and_the_Classification.RData")

# Sentiment model 
num_train <- as.factor(sent_train_target) %>% as.numeric() - 1
sent_train <- xgb.DMatrix(as.matrix(sent_train),
                          label=num_train)
sent_test  <- xgb.DMatrix(as.matrix(sent_test),
                          label=num_test)

# Bag of words TF model
num_train <- as.factor(bow_train_target) %>% as.numeric() - 1
bow_train <- xgb.DMatrix(bow_train,
                         label=num_train)
bow_test  <- xgb.DMatrix(bow_test,
                         label=num_test)

# Bag of words TF-IDF model
num_train <- as.factor(bowtfidf_train_target) %>% as.numeric() - 1
bowtfidf_train <- xgb.DMatrix(bowtfidf_train,
                              label=num_train)
bowtfidf_test  <- xgb.DMatrix(bowtfidf_test,
                              label=num_test)

# Word Embeddings (Sum-SQRT) model
num_train <- as.factor(we_ss_train_target) %>% as.numeric() - 1
we_ss_train <- xgb.DMatrix(we_ss_train,
                           label=num_train)
we_ss_test  <- xgb.DMatrix(we_ss_test,
                           label=num_test)


# Global parameters
num_class <- 7

# cross validation
cv_tune <- function(data, iterations = 25, num_class = 7, 
                    nrounds = 25, nfold = 4, 
                    eval_metric = "mlogloss", 
                    objective = "multi:softprob") {
  best_param = list()
  best_seednumber = 2020
  best_logloss = Inf
  best_logloss_index = 0
  
  for (i in 1:iterations) {
      param <- list(
            objective = objective,
            num_class = num_class,
            eval_metric = eval_metric,
            eta = runif(1, min = .001, max = .5),
            max_depth = sample(4:8, 1),
            subsample = 1
            )
      seed.number <- sample.int(10000, 1)[[1]]
      set.seed(seed.number)          
      cross_val <- xgb.cv(data = data, param = param, 
                          verbose = F, nthread = 8, 
                          early_stopping_rounds = 5, maximize = FALSE,
                          nrounds = nrounds, nfold = nfold)
      
      eval_metrics <- cross_val$evaluation_log[, "test_mlogloss_mean"] %>%
                      as.data.frame()
      min_logloss <- min(eval_metrics)
      min_logloss_index <- which.min(unlist(eval_metrics))
      
      if (min_logloss < best_logloss) {
          best_eval <- eval_metrics
          best_logloss <- min_logloss
          best_nround <- min_logloss_index
          best_seednumber <- seed.number
          best_param <- param
      }
  }
  
  return(list(best_nround, best_param, best_eval))
}

# Results
pred_test <- data.frame(matrix(nrow=length(num_test), ncol=7*4))
pred_train <- data.frame(matrix(nrow=length(num_train), ncol=7*4))
```


## Sentiment Model
```{r}
# cross validation
cv_best <- cv_tune(data = sent_train)
pasteNQ("Best NRound:")
cv_best[[1]] %>% as.numeric()
pasteNQ("Best Params:")
cv_best[[2]]

# best model
sent_model <- xgboost(data=sent_train, verbose=F,
                      nrounds=cv_best[[1]], param=cv_best[[2]])

# prediction
cols <- 1:7
pred_test[ , cols] <- predict(sent_model, sent_test) %>% 
                              matrix(ncol=num_class, byrow=TRUE)
results_test[ , "Sent_Label"] <- max.col(pred_test[ , cols])

# error and accuracy measure
results_test[ , "Sent_Label"] <- factor(results_test[ , "Sent_Label"],
                                  labels = unique(results_test$Target))
sent_acc <- confusionMatrix(results_test$Sent_Label, 
                            results_test$Target)
round( sent_acc$overall["Accuracy"], 2 )

# Graph
## Balanced Accuracy
sent_acc$byClass %>% 
  as.data.frame() %>%
  ggplot(aes(x = `Balanced Accuracy` %>% as.numeric()*100, 
             y = titles, fill = titles)) +
  geom_bar(stat = "identity") +
  xlim(0, 100) +
  labs(title="Balanced Accuracy",
       y="Book",
       x="Balanced Accuracy (%)") + 
  scale_fill_manual(values = c("#946B2D", "#0D6217", "#000A90", 
                               "#AAAAAA", "#000000", "#7F0909", "#FFC500")) +
  Grph_theme_facet() 

## Feature Importance
importance_matrix <- xgb.importance(model = sent_model)
features_gb <- importance_matrix[1:10,]
ggplot(features_gb, mapping=aes(x=reorder(Feature, Gain), y=Gain,
                                fill="hotpink")) + 
  coord_flip() +
  geom_bar(position="dodge",stat="identity") + 
  labs(title = "Top Ten Features",
       subtitle = "Sentiment Model",
       y = "Fractional Contribution",
       x = "Feature") + 
  guides(fill=FALSE) +
  Grph_theme_facet()
```


## Bag of Words TF Model
```{r}
# cross validation
cv_best <- cv_tune(data = bow_train)
pasteNQ("Best NRound:")
cv_best[[1]] %>% as.numeric()
pasteNQ("Best Params:")
cv_best[[2]]

# best model
bow_model <- xgboost(data=bow_train, verbose=F,
                      nrounds=cv_best[[1]], param=cv_best[[2]])

# prediction
cols <- 8:14
pred_test[ , cols] <- predict(bow_model, bow_test) %>% 
                              matrix(ncol=num_class, byrow=TRUE)
results_test[ , "BoW_Label"] <- max.col(pred_test[ , cols])

# error and accuracy measure
results_test[ , "BoW_Label"] <- factor(results_test[ , "BoW_Label"],
                                  labels = unique(results_test$Target))
bow_acc <- confusionMatrix(results_test$BoW_Label, 
                           results_test$Target)
round( bow_acc$overall["Accuracy"], 2 )

# Graph
## Balanced Accuracy
bow_acc$byClass %>% 
  as.data.frame() %>%
  ggplot(aes(x = `Balanced Accuracy` %>% as.numeric()*100, 
             y = titles, fill = titles)) +
  geom_bar(stat = "identity") +
  xlim(0, 100) +
  labs(title="Balanced Accuracy",
       y="Book",
       x="Balanced Accuracy (%)") + 
  scale_fill_manual(values = c("#946B2D", "#0D6217", "#000A90", 
                               "#AAAAAA", "#000000", "#7F0909", "#FFC500")) +
  Grph_theme_facet()

## Feature Importance
importance_matrix <- xgb.importance(model = bow_model)
features_gb <- importance_matrix[1:10,]
ggplot(features_gb, mapping=aes(x=reorder(Feature, Gain), y=Gain, 
                                fill="green")) + 
  coord_flip() +
  geom_bar(position="dodge",stat="identity") + 
  labs(title = "Top Ten Features",
       subtitle = "Bag of Words (TF) Model",
       y = "Fractional Contribution",
       x = "Feature") + 
  guides(fill=FALSE) +
  Grph_theme_facet()
```


## Bag of Words (TF-IDF) Model
```{r}
# cross validation
cv_best <- cv_tune(data = bowtfidf_train)
pasteNQ("Best NRound:")
cv_best[[1]] %>% as.numeric()
pasteNQ("Best Params:")
cv_best[[2]]

# best model
bowtfidf_model <- xgboost(data=bowtfidf_train, verbose=F,
                      nrounds=cv_best[[1]], param=cv_best[[2]])

# prediction
cols <- 15:21
pred_test[ , cols] <- predict(bowtfidf_model, bowtfidf_test) %>% 
                              matrix(ncol=num_class, byrow=TRUE)
results_test[ , "BoWtfidf_Label"] <- max.col(pred_test[ , cols])

# error and accuracy measure
results_test[ , "BoWtfidf_Label"] <- factor(results_test[ , "BoWtfidf_Label"],
                                  labels = unique(results_test$Target))
bowtfidf_acc <- confusionMatrix(results_test$BoWtfidf_Label, 
                           results_test$Target)
round( bowtfidf_acc$overall["Accuracy"], 2 )

# Graph
## Balanced Accuracy
bowtfidf_acc$byClass %>% 
  as.data.frame() %>%
  ggplot(aes(x = `Balanced Accuracy` %>% as.numeric()*100, 
             y = titles, fill = titles)) +
  geom_bar(stat = "identity") +
  xlim(0, 100) +
  labs(title="Balanced Accuracy",
       y="Book",
       x="Balanced Accuracy (%)") + 
  scale_fill_manual(values = c("#946B2D", "#0D6217", "#000A90", 
                               "#AAAAAA", "#000000", "#7F0909", "#FFC500")) +
  Grph_theme_facet() 

## Feature Importance
importance_matrix <- xgb.importance(model = bowtfidf_model)
features_gb <- importance_matrix[1:10,]
ggplot(features_gb, mapping=aes(x=reorder(Feature, Gain), y=Gain, 
                                fill="green")) + 
  coord_flip() +
  geom_bar(position="dodge",stat="identity") + 
  labs(title = "Top Ten Features",
       subtitle = "Bag of Words (TF-IDF) Model",
       y = "Fractional Contribution",
       x = "Feature") + 
  guides(fill=FALSE) +
  Grph_theme_facet()
```


## Word Embeddings (Sum-SQRT) Model
```{r}
# cross validation
cv_best <- cv_tune(data = we_ss_train)
pasteNQ("Best NRound:")
cv_best[[1]] %>% as.numeric()
pasteNQ("Best Params:")
cv_best[[2]]

# best model
we_ss_model <- xgboost(data=we_ss_train, verbose=F,
                    nrounds=cv_best[[1]], param=cv_best[[2]])

# prediction
cols <- 22:28
pred_test[ , cols] <- predict(we_ss_model, we_ss_test) %>% 
                     matrix(ncol=num_class, byrow=TRUE)
results_test[ , "WE_SS_Label"] <- max.col(pred_test[ , cols])

# error and accuracy measure
results_test[ , "WE_SS_Label"] <- factor(results_test[ , "WE_SS_Label"],
                                  labels = unique(results_test$Target))
we_ss_acc <- confusionMatrix(results_test$WE_SS_Label, 
                          results_test$Target)
round( we_ss_acc$overall["Accuracy"], 2 )

# Graph
## Balanced Accuracy
we_ss_acc$byClass %>% 
  as.data.frame() %>%
  ggplot(aes(x = `Balanced Accuracy` %>% as.numeric()*100, 
             y = titles, fill = titles)) +
  geom_bar(stat = "identity") +
  xlim(0, 100) +
  labs(title="Balanced Accuracy",
       y="Book",
       x="Balanced Accuracy (%)") + 
  scale_fill_manual(values = c("#946B2D", "#0D6217", "#000A90", 
                               "#AAAAAA", "#000000", "#7F0909", "#FFC500")) +
  Grph_theme_facet()
```


# V) Perform Stacked Ensemble Modeling
**Description:** Ensemble 4 bottom layer models with top layer model
**Purpose:** Take strengths of each model and minimize each model's weaknesses    
     
* Resample train data for each of the 4 models with the same seed to ensure all rows contain same documents across bottom-layer models
* Use 4 training models to generate predicted probabilities and save as seven columns per model in a new data frame (28 columns in total)
* Model bottom layer models with top layer K Nearest Neighbors (KNN) to priviledge model strengths

```{r}
# Sentiment model 
sent_top_train <- xgb.DMatrix(as.matrix(sent_top_train),
                              label=num_train)

# Bag of words TF model
bow_top_train <- xgb.DMatrix(bow_top_train,
                             label=num_train)

# Bag of words TF-IDF model
bowtfidf_top_train <- xgb.DMatrix(bowtfidf_top_train,
                                  label=num_train)

# Word Embeddings (Sum-SQRT) model
we_ss_top_train <- xgb.DMatrix(we_ss_top_train,
                               label=num_train)

#Predicting the training probabilities
pred_train[ , 1:7]   <- predict(sent_model, sent_top_train) %>% 
                                matrix(ncol=num_class, byrow=TRUE) 

pred_train[ , 8:14]  <- predict(bow_model, bow_top_train) %>% 
                                matrix(ncol=num_class, byrow=TRUE) 

pred_train[ , 15:21] <- predict(bowtfidf_model, bowtfidf_top_train) %>% 
                                matrix(ncol=num_class, byrow=TRUE) 

pred_train[ , 22:28] <- predict(we_ss_model, we_ss_top_train) %>% 
                                matrix(ncol=num_class, byrow=TRUE) 
``` 


## Top Layer (KNN)
```{r}
top_knn_train <- pred_train %>% data.frame()
top_knn_train$target <- top_train_target

# cross validation
trctrl <- trainControl(method = "repeatedcv", number = 4, repeats = 3)
model_top_knn <- train(
  target ~ .,
  data = top_knn_train,
  method = "knn",
  trControl = trctrl,
  preProcess = c("center", "scale"),
  tuneLength = 10
)

# prediction
results_top_knn_test <- data.frame(matrix(nrow=nrow(test), ncol=7))
results_top_knn_test[ , "Top_KNN_Label"] <- predict(model_top_knn, pred_test) 

# error and accuracy measure
results_test[ , "Top_KNN_Label"] <- factor(results_top_knn_test[ , "Top_KNN_Label"],
                                  labels = unique(results_test$Target))
top_knn_acc <- confusionMatrix(results_test$Top_KNN_Label, 
                           results_test$Target)
top_knn_acc$overall[1]

# Graph
top_knn_acc$byClass %>% 
  as.data.frame() %>%
  ggplot(aes(x = `Balanced Accuracy` %>% as.numeric()*100, 
             y = titles, fill = titles)) +
  geom_bar(stat = "identity") +
  xlim(0, 100) +
  labs(title="Balanced Accuracy",
       y="Book",
       x="Balanced Accuracy (%)") + 
  scale_fill_manual(values = c("#946B2D", "#0D6217", "#000A90", 
                               "#AAAAAA", "#000000", "#7F0909", "#FFC500")) +
  Grph_theme_facet()
```


# VI) Determine Final Model Performance

**Description:** Test results of stacked model ensemble on testing data
**Purpose:** Ensure model process and outcome is generalizable

```{r}
pasteNQ("Sentiment Model")
sent_acc$overall["Accuracy"]
cat("\n")

pasteNQ("Bag of Words (TF) Model")
bow_acc$overall["Accuracy"]
cat("\n")

pasteNQ("Bag of Words (TF-IDF) Model")
bowtfidf_acc$overall["Accuracy"]
cat("\n")

pasteNQ("Word Embedding Model")
we_ss_acc$overall["Accuracy"]
cat("\n")

pasteNQ("Top Layer (KNN) Model")
top_knn_acc$overall["Accuracy"]


# Graph Balanced Accuracy
bal_acc <- cbind(titles, "1 Sentiment", sent_acc$byClass[ , "Balanced Accuracy"]) %>%
     rbind(cbind(titles, "2 Bag of Words (TF)", bow_acc$byClass[ , "Balanced Accuracy"])) %>%
     rbind(cbind(titles, "3 Bag of Words (TF-IDF)", bowtfidf_acc$byClass[ , "Balanced Accuracy"])) %>%
     rbind(cbind(titles, "4 Word Embedding", we_ss_acc$byClass[ , "Balanced Accuracy"])) %>% 
     rbind(cbind(titles, "5 Top Layer", top_knn_acc$byClass[ , "Balanced Accuracy"])) %>% 
  as_tibble()
colnames(bal_acc) <- c("Book", "Model", "Balanced Accuracy")

bal_acc %>% 
  ggplot(aes(x = `Balanced Accuracy` %>% as.numeric()*100, 
             y = Book,
             fill = Model)) +
  geom_bar(stat = "identity") +
  facet_wrap(~Model) +
  labs(title="Balanced Accuracy",
       y="Book",
       x="Balanced Accuracy (%)") + 
  scale_fill_manual(values = c("#0D6217", "#7F0909", "#000A90", "#FFC500", 
                               "#AAAAAA", "#000000")) +
  Grph_theme_facet() 

# Graph COnfusion Matrix
ggplot(results_test, 
       aes(Target, Top_KNN_Label, color=Target)) + 
  geom_jitter(size=1) + 
  labs(title="Confusion Matrix",
       subtitle="Predicted vs. Observed",
       y="Predicted",
       x="Observed") + 
  scale_color_manual(values = c("#946B2D", "#0D6217", "#000A90", 
                               "#AAAAAA", "#000000", "#7F0909", "#FFC500")) +
  Grph_theme_facet() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```


# Save
```{r}
save(train, test, target_test, 
     pred_train, pred_test, 
     sent_train, sent_test, sent_top_train, sent_model,
     bow_train, bow_test, bow_top_train, bow_model,
     bowtfidf_train, bowtfidf_test, bowtfidf_top_train, bowtfidf_model, tfidf,
     we_ss_train, we_ss_test, we_ss_top_train, we_ss_model,
     results_test, results_top_knn_test,
     model_top_knn, 
     sent_acc, bow_acc, bowtfidf_acc, we_ss_acc, top_knn_acc,
     file = "Harry_Potter_and_the_Classification_Models.RData")
```


